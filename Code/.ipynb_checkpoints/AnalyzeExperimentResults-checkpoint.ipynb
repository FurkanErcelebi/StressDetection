{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11305,
     "status": "ok",
     "timestamp": 1738143834583,
     "user": {
      "displayName": "İbrahim Furkan",
      "userId": "03214658540359897285"
     },
     "user_tz": -180
    },
    "id": "qsSA9d_Wjeoe",
    "outputId": "54513011-a9c5-4be9-9e21-712a67a3a93d"
   },
   "outputs": [],
   "source": [
    "# !pip install torch==1.13.1+cu117 torchvision==0.14.1+cu117 torchaudio==0.13.1 --extra-index-url https://download.pytorch.org/whl/cu117 torchmetrics torchinfo\n",
    "!pip install torcheval torchmetrics torchinfo --extra-index-url https://download.pytorch.org/whl/cu117"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2247,
     "status": "ok",
     "timestamp": 1738143836822,
     "user": {
      "displayName": "İbrahim Furkan",
      "userId": "03214658540359897285"
     },
     "user_tz": -180
    },
    "id": "km_rSCRnedmA",
    "outputId": "ea1ccc14-99fd-46bd-e196-03ccd2e62d18"
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade tensorboard 2.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 519,
     "status": "ok",
     "timestamp": 1738144020483,
     "user": {
      "displayName": "İbrahim Furkan",
      "userId": "03214658540359897285"
     },
     "user_tz": -180
    },
    "id": "bq2hIzlMUCw_",
    "outputId": "1cf2bb4b-7c35-4b38-ed4d-3357ee9c5a00"
   },
   "outputs": [],
   "source": [
    "# from this site https://github.com/KastoneX/AutoData-Analysis-and-Price-Prediction-of-Used-Cars\n",
    "\n",
    "import sys\n",
    "import io\n",
    "import time\n",
    "import random\n",
    "import math\n",
    "import os\n",
    "import copy\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder,MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score, f1_score,accuracy_score,recall_score,roc_auc_score,roc_curve, confusion_matrix\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchinfo import summary\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import DataLoader, TensorDataset, ConcatDataset\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torchmetrics.functional.classification import auroc # auc\n",
    "from collections import defaultdict\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torcheval.metrics.functional import binary_f1_score, binary_accuracy, binary_precision\n",
    "from torcheval.metrics.functional.classification import binary_recall\n",
    "\n",
    "# from tensorboard.plugins\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "sns.set(style='whitegrid', palette='muted', font_scale=1.2)\n",
    "\n",
    "Colour_Palette = ['#01BEFE', '#FF7D00', '#FFDD00', '#FF006D', '#ADFF02', '#8F00FF']\n",
    "sns.set_palette(sns.color_palette(Colour_Palette))\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "if torch.cuda.is_available():\n",
    "  print(torch.cuda.get_device_name())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 37359,
     "status": "ok",
     "timestamp": 1738143897536,
     "user": {
      "displayName": "İbrahim Furkan",
      "userId": "03214658540359897285"
     },
     "user_tz": -180
    },
    "id": "CD821SbEde2-",
    "outputId": "10e7a8fd-e22f-4024-c959-b7c78ab4b39e"
   },
   "outputs": [],
   "source": [
    "DRIVE_MOUNT_POINT = '/content/drive'\n",
    "\n",
    "from google.colab import drive\n",
    "\n",
    "drive.mount(DRIVE_MOUNT_POINT)\n",
    "print('Data source import complete.')\n",
    "\n",
    "EXPR_PATH = os.environ.get('EXPR_RESULT_PATH')\n",
    "EXPR_PATH_IMAGES = os.path.join(EXPR_PATH,'ExperimentResultImages')\n",
    "\n",
    "dotenv.load_dotenv('/content/drive/MyDrive/.env')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "util_script_path = os.environ.get('UTIL_SCRIPT_PATH')\n",
    "if util_script_path is not None:\n",
    "  sys.path.insert(0, util_script_path)\n",
    "else:\n",
    "  print(\"Warning: UTIL_SCRIPT_PATH environment variable is not set.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6118,
     "status": "ok",
     "timestamp": 1738143903649,
     "user": {
      "displayName": "İbrahim Furkan",
      "userId": "03214658540359897285"
     },
     "user_tz": -180
    },
    "id": "Bcu447iLQPzh"
   },
   "outputs": [],
   "source": [
    "\n",
    "from stress_models import  LSTMModel, AlexNetModifiedVersion, ResNet18ModifiedVersion\n",
    "from preprocess_and_train_datasets import get_samples_as_dataloader, get_classification_distribution\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 269,
     "status": "ok",
     "timestamp": 1737796056107,
     "user": {
      "displayName": "Furkan Ercelebi",
      "userId": "09395212391711469742"
     },
     "user_tz": -180
    },
    "id": "39BavOR20a3_",
    "outputId": "be1efc7b-1ff9-4fc8-9b92-dd3f857fe1f8"
   },
   "outputs": [],
   "source": [
    "!ls -ltr '{util_script_path}' | grep 'LSTM' | tail -n 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 233,
     "status": "ok",
     "timestamp": 1737822245736,
     "user": {
      "displayName": "Furkan Ercelebi",
      "userId": "09395212391711469742"
     },
     "user_tz": -180
    },
    "id": "k5eko8kx1vCf",
    "outputId": "be809ab9-c7db-4c55-9e8f-e03082e50916"
   },
   "outputs": [],
   "source": [
    "!ls -ltr '{util_script_path}' | grep 'AlexNet' | tail -n 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 407,
     "status": "ok",
     "timestamp": 1738074589448,
     "user": {
      "displayName": "Furkan Ercelebi",
      "userId": "09395212391711469742"
     },
     "user_tz": -180
    },
    "id": "Rw9DhiQQzFSs",
    "outputId": "4a7551a2-7d22-40e4-b031-88a62e7fd395"
   },
   "outputs": [],
   "source": [
    "!ls -ltr '{EXPR_PATH}' | grep 'LSTM_Stress' | tail -n 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 535,
     "status": "ok",
     "timestamp": 1738144630274,
     "user": {
      "displayName": "İbrahim Furkan",
      "userId": "03214658540359897285"
     },
     "user_tz": -180
    },
    "id": "FkP1938mtgeL",
    "outputId": "862f13b9-48f4-4e5e-9d71-e3696fa11498"
   },
   "outputs": [],
   "source": [
    "!ls -ltr '{EXPR_PATH}' | grep 'LSTM_V3_Stress' | tail -n 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 280,
     "status": "ok",
     "timestamp": 1738082992328,
     "user": {
      "displayName": "Furkan Ercelebi",
      "userId": "09395212391711469742"
     },
     "user_tz": -180
    },
    "id": "arrxztkJiu7Y",
    "outputId": "efa219d4-918c-4074-ed34-311a8f017eea"
   },
   "outputs": [],
   "source": [
    "!ls -ltr '{EXPR_PATH}' | grep 'LSTM_V4_Stress' | tail -n 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 619,
     "status": "ok",
     "timestamp": 1737828649140,
     "user": {
      "displayName": "Furkan Ercelebi",
      "userId": "09395212391711469742"
     },
     "user_tz": -180
    },
    "id": "T8lyBAzulsvf",
    "outputId": "16b0e330-bf7f-4f50-9595-97f8bbb24854"
   },
   "outputs": [],
   "source": [
    "!ls -ltr '{EXPR_PATH}' | grep 'AlexNet' | tail -n 20\n",
    "# !ls -ltr '/content/drive/MyDrive/BitirmeProje/BitirmeProje_3/ExperimentResults/LSTM_Stress_Detection__Seperated_Augmentation_And_Non_Balanced_1_2_Datasets_For_DP_2-AP_1-FP_5-TP_15'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1738144067254,
     "user": {
      "displayName": "İbrahim Furkan",
      "userId": "03214658540359897285"
     },
     "user_tz": -180
    },
    "id": "0_rBkRh_jkkU"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorboard as tb\n",
    "from packaging import version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1097,
     "status": "ok",
     "timestamp": 1738144066450,
     "user": {
      "displayName": "İbrahim Furkan",
      "userId": "03214658540359897285"
     },
     "user_tz": -180
    },
    "id": "SJFJW-rdgsl8"
   },
   "outputs": [],
   "source": [
    "import traceback\n",
    "from tensorboard.backend.event_processing.event_accumulator import EventAccumulator, TENSORS\n",
    "\n",
    "DEFAULT_SIZE_GUIDANCE = {\n",
    "        \"compressedHistograms\": 1,\n",
    "        \"images\": 1,\n",
    "        \"scalars\": 0,  # 0 means load all\n",
    "        \"histograms\": 1,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 485,
     "status": "ok",
     "timestamp": 1738144064396,
     "user": {
      "displayName": "İbrahim Furkan",
      "userId": "03214658540359897285"
     },
     "user_tz": -180
    },
    "id": "C7sXyNmsgUMG"
   },
   "outputs": [],
   "source": [
    "def tflog2pandas(path, scalar_metric_name):\n",
    "    # from other site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1738144068816,
     "user": {
      "displayName": "İbrahim Furkan",
      "userId": "03214658540359897285"
     },
     "user_tz": -180
    },
    "id": "BzcYR4zMWzuB"
   },
   "outputs": [],
   "source": [
    "def get_train_accuracy_values_as_df_from_log_path(log_path):\n",
    "\n",
    "  mean_accuracy_train = []\n",
    "  mean_accuracy_val = []\n",
    "\n",
    "  kfold_range = int((len(os.listdir(log_path)) - 1) / 5)\n",
    "\n",
    "  for i in range(kfold_range):\n",
    "\n",
    "    log_dir = f'{log_path}/Accuracy - {(i + 1)}_val/acc'\n",
    "    ratio_values = tflog2pandas(os.path.join(log_dir, os.listdir(log_dir)[0]), f'Accuracy - {(i + 1)}')\n",
    "    if i > 0:\n",
    "      if len(mean_accuracy_val[0]) == len(ratio_values):\n",
    "        mean_accuracy_val.append(list(ratio_values))\n",
    "    else:\n",
    "      mean_accuracy_val.append(list(ratio_values))\n",
    "\n",
    "    log_dir = f'{log_path}/Accuracy - {(i + 1)}_train/acc'\n",
    "    ratio_values = tflog2pandas(os.path.join(log_dir, os.listdir(log_dir)[0]), f'Accuracy - {(i + 1)}')\n",
    "    if i > 0:\n",
    "      if len(mean_accuracy_val[0]) == len(ratio_values):\n",
    "        mean_accuracy_train.append(list(ratio_values))\n",
    "    else:\n",
    "      mean_accuracy_train.append(list(ratio_values))\n",
    "\n",
    "\n",
    "  main_log_df = pd.DataFrame()\n",
    "\n",
    "  log_df = pd.DataFrame()\n",
    "  log_df['Ratio'] = np.mean(mean_accuracy_val, axis=0)\n",
    "  log_df['Phase'] = ['Validation' for ratio_idx in range(len(log_df['Ratio']))]\n",
    "  log_df['Epoch'] = [epoch_idx + 1 for epoch_idx in range(len(log_df['Ratio']))]\n",
    "  main_log_df = pd.concat([main_log_df, log_df])\n",
    "\n",
    "  log_df = pd.DataFrame()\n",
    "  log_df['Ratio'] = np.mean(mean_accuracy_train, axis=0)\n",
    "  log_df['Phase'] = ['Train' for ratio_idx in range(len(log_df['Ratio']))]\n",
    "  log_df['Epoch'] = [epoch_idx + 1 for epoch_idx in range(len(log_df['Ratio']))]\n",
    "  main_log_df = pd.concat([main_log_df, log_df])\n",
    "\n",
    "  return main_log_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 308,
     "status": "ok",
     "timestamp": 1737847079576,
     "user": {
      "displayName": "Furkan Ercelebi",
      "userId": "09395212391711469742"
     },
     "user_tz": -180
    },
    "id": "K7Jsz9VlIKZQ",
    "outputId": "b1f15d4a-3465-460c-cf75-6e91314c8f22"
   },
   "outputs": [],
   "source": [
    "LSTM_LOG_DIRS = [sample_file for sample_file in sorted(Path(EXPR_PATH).iterdir(), key=os.path.getmtime) if sample_file.is_dir() and sample_file.name.startswith('LSTM_Stress')]\n",
    "\n",
    "ignored_index_list = [7, 13, 14]\n",
    "# ignored_index_list = []\n",
    "\n",
    "lstm_procedure_path_infos = {}\n",
    "\n",
    "for log_dir_idx in range(1, 16):\n",
    "  if log_dir_idx not in ignored_index_list:\n",
    "\n",
    "    procedure_key = ''\n",
    "    sample_log_dir = LSTM_LOG_DIRS[- log_dir_idx].name\n",
    "    if 'Non_Balance' in sample_log_dir:\n",
    "      procedure_key = 'NON_BLNC'\n",
    "    else:\n",
    "      procedure_key = 'BLNC'\n",
    "\n",
    "    if 'AP_1' in sample_log_dir and '__Seperated_Augmentation' in sample_log_dir:\n",
    "      procedure_key = f'{procedure_key}--ONL_ORG'\n",
    "    elif 'AP_ALL' in sample_log_dir and '__Seperated_Augmentation' in sample_log_dir:\n",
    "      procedure_key = f'{procedure_key}--ORG_AUG_SEP'\n",
    "    else:\n",
    "      procedure_key = f'{procedure_key}--ORG_AUG_MIX'\n",
    "\n",
    "    if 'FP_2' in sample_log_dir:\n",
    "      procedure_key = f'{procedure_key}--ALL'\n",
    "    else:\n",
    "      procedure_key = f'{procedure_key}--TD'\n",
    "\n",
    "    print(sample_log_dir, procedure_key)\n",
    "    lstm_procedure_path_infos[procedure_key] = sample_log_dir\n",
    "\n",
    "\n",
    "print(lstm_procedure_path_infos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 32809,
     "status": "ok",
     "timestamp": 1737848885399,
     "user": {
      "displayName": "Furkan Ercelebi",
      "userId": "09395212391711469742"
     },
     "user_tz": -180
    },
    "id": "SByv9uaUrWwl",
    "outputId": "35966b3a-71ab-4c52-a268-e3f1cda44868"
   },
   "outputs": [],
   "source": [
    "\n",
    "lstm_accuracy_df_infos = {}\n",
    "\n",
    "for lstm_procedure_path_infos_key in lstm_procedure_path_infos.keys():\n",
    "  kfold_logs_path = f'{EXPR_PATH}/{lstm_procedure_path_infos[lstm_procedure_path_infos_key]}/'\n",
    "\n",
    "  sample_files = [sample_file.name for sample_file in sorted(Path(kfold_logs_path).iterdir(), key=os.path.getmtime) if sample_file.is_dir() and sample_file.name.startswith('run')]\n",
    "\n",
    "  kfold_logs_path = os.path.join(kfold_logs_path, sample_files[-1])\n",
    "  for __ in range(4):\n",
    "    kfold_logs_path = os.path.join(kfold_logs_path, os.listdir(kfold_logs_path)[0])\n",
    "\n",
    "  accuracy_df = get_train_accuracy_values_as_df_from_log_path(kfold_logs_path)\n",
    "  lstm_accuracy_df_infos[lstm_procedure_path_infos_key] = accuracy_df.copy()\n",
    "  print(lstm_procedure_path_infos_key, accuracy_df.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 236,
     "status": "ok",
     "timestamp": 1737847117206,
     "user": {
      "displayName": "Furkan Ercelebi",
      "userId": "09395212391711469742"
     },
     "user_tz": -180
    },
    "id": "lSxcrJMJMeG7",
    "outputId": "d61fc3b6-fe91-4192-c0cb-6e8ffe325f0d"
   },
   "outputs": [],
   "source": [
    "LSTM_V2_LOG_DIRS = [sample_file for sample_file in sorted(Path(EXPR_PATH).iterdir(), key=os.path.getmtime) if sample_file.is_dir() and sample_file.name.startswith('LSTM_V2_Stress')]\n",
    "\n",
    "lstm_v2_procedure_path_infos = {}\n",
    "\n",
    "for log_dir_idx in range(0, 12):\n",
    "\n",
    "  procedure_key = ''\n",
    "  sample_log_dir = LSTM_V2_LOG_DIRS[log_dir_idx].name\n",
    "  if 'Non_Balance' in sample_log_dir:\n",
    "    procedure_key = 'NON_BLNC'\n",
    "  else:\n",
    "    procedure_key = 'BLNC'\n",
    "\n",
    "  if 'AP_1' in sample_log_dir and '__Seperated_Augmentation' in sample_log_dir:\n",
    "    procedure_key = f'{procedure_key}--ONL_ORG'\n",
    "  elif 'AP_ALL' in sample_log_dir and '__Seperated_Augmentation' in sample_log_dir:\n",
    "    procedure_key = f'{procedure_key}--ORG_AUG_SEP'\n",
    "  else:\n",
    "    procedure_key = f'{procedure_key}--ORG_AUG_MIX'\n",
    "\n",
    "  if 'FP_2' in sample_log_dir:\n",
    "    procedure_key = f'{procedure_key}--ALL'\n",
    "  else:\n",
    "    procedure_key = f'{procedure_key}--TD'\n",
    "\n",
    "  print(sample_log_dir, procedure_key)\n",
    "  lstm_v2_procedure_path_infos[procedure_key] = sample_log_dir\n",
    "\n",
    "\n",
    "print(lstm_v2_procedure_path_infos)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25631,
     "status": "ok",
     "timestamp": 1737848911027,
     "user": {
      "displayName": "Furkan Ercelebi",
      "userId": "09395212391711469742"
     },
     "user_tz": -180
    },
    "id": "eVmlyFpFwvgc",
    "outputId": "2a304521-39cf-43fa-ddd1-9a3b9d4fcb86"
   },
   "outputs": [],
   "source": [
    "\n",
    "lstm_v2_accuracy_df_infos = {}\n",
    "\n",
    "for lstm_v2_procedure_path_infos_key in lstm_v2_procedure_path_infos.keys():\n",
    "  kfold_logs_path = f'{EXPR_PATH}/{lstm_v2_procedure_path_infos[lstm_v2_procedure_path_infos_key]}/'\n",
    "\n",
    "  sample_files = [sample_file.name for sample_file in sorted(Path(kfold_logs_path).iterdir(), key=os.path.getmtime) if sample_file.is_dir() and sample_file.name.startswith('run')]\n",
    "\n",
    "  kfold_logs_path = os.path.join(kfold_logs_path, sample_files[-1])\n",
    "  for __ in range(4):\n",
    "    kfold_logs_path = os.path.join(kfold_logs_path, os.listdir(kfold_logs_path)[0])\n",
    "\n",
    "  accuracy_df = get_train_accuracy_values_as_df_from_log_path(kfold_logs_path)\n",
    "  lstm_v2_accuracy_df_infos[lstm_v2_procedure_path_infos_key] = accuracy_df.copy()\n",
    "  print(lstm_v2_procedure_path_infos_key, accuracy_df.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 479,
     "status": "ok",
     "timestamp": 1738144074516,
     "user": {
      "displayName": "İbrahim Furkan",
      "userId": "03214658540359897285"
     },
     "user_tz": -180
    },
    "id": "oK9MDu3K4kxp",
    "outputId": "4e1460fd-a3c5-4055-dd1f-23817cf00596"
   },
   "outputs": [],
   "source": [
    "LSTM_V3_LOG_DIRS = [sample_file for sample_file in sorted(Path(EXPR_PATH).iterdir(), key=os.path.getmtime) if sample_file.is_dir() and sample_file.name.startswith('LSTM_V3_Stress')]\n",
    "\n",
    "ignored_index_list = []\n",
    "\n",
    "lstm_v3_procedure_path_infos = {}\n",
    "\n",
    "for log_dir_idx in range(len(LSTM_V3_LOG_DIRS)):\n",
    "  if log_dir_idx not in ignored_index_list:\n",
    "\n",
    "    procedure_key = ''\n",
    "    sample_log_dir = LSTM_V3_LOG_DIRS[- log_dir_idx].name\n",
    "    if 'Non_Balance' in sample_log_dir:\n",
    "      procedure_key = 'NON_BLNC'\n",
    "    else:\n",
    "      procedure_key = 'BLNC'\n",
    "\n",
    "    if 'AP_1' in sample_log_dir and '__Seperated_Augmentation' in sample_log_dir:\n",
    "      procedure_key = f'{procedure_key}--ONL_ORG'\n",
    "    elif 'AP_ALL' in sample_log_dir and '__Seperated_Augmentation' in sample_log_dir:\n",
    "      procedure_key = f'{procedure_key}--ORG_AUG_SEP'\n",
    "    else:\n",
    "      procedure_key = f'{procedure_key}--ORG_AUG_MIX'\n",
    "\n",
    "    if 'FP_2' in sample_log_dir:\n",
    "      procedure_key = f'{procedure_key}--ALL'\n",
    "    elif 'FP_5' in sample_log_dir:\n",
    "      procedure_key = f'{procedure_key}--TD'\n",
    "    else:\n",
    "      procedure_key = f'{procedure_key}--ALL'\n",
    "\n",
    "    if 'Raw' in sample_log_dir:\n",
    "      procedure_key = f'{procedure_key}--RAW'\n",
    "    else:\n",
    "      procedure_key = f'{procedure_key}--NON_RAW'\n",
    "\n",
    "    print(sample_log_dir, procedure_key)\n",
    "    lstm_v3_procedure_path_infos[procedure_key] = sample_log_dir\n",
    "\n",
    "\n",
    "print(lstm_v3_procedure_path_infos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1041,
     "status": "ok",
     "timestamp": 1738085722436,
     "user": {
      "displayName": "Furkan Ercelebi",
      "userId": "09395212391711469742"
     },
     "user_tz": -180
    },
    "id": "XHrKMaX06CMu",
    "outputId": "df503b92-46f6-4fd9-9520-210518672480"
   },
   "outputs": [],
   "source": [
    "\n",
    "lstm_v3_accuracy_df_infos = {}\n",
    "\n",
    "for lstm_v3_procedure_path_infos_key in lstm_v3_procedure_path_infos.keys():\n",
    "  kfold_logs_path = f'{EXPR_PATH}/{lstm_v3_procedure_path_infos[lstm_v3_procedure_path_infos_key]}/'\n",
    "\n",
    "  sample_files = [sample_file.name for sample_file in sorted(Path(kfold_logs_path).iterdir(), key=os.path.getmtime) if sample_file.is_dir() and sample_file.name.startswith('run')]\n",
    "\n",
    "  kfold_logs_path = os.path.join(kfold_logs_path, sample_files[-1])\n",
    "  for __ in range(4):\n",
    "    kfold_logs_path = os.path.join(kfold_logs_path, os.listdir(kfold_logs_path)[0])\n",
    "\n",
    "  accuracy_df = get_train_accuracy_values_as_df_from_log_path(kfold_logs_path)\n",
    "  lstm_v3_accuracy_df_infos[lstm_v3_procedure_path_infos_key] = accuracy_df.copy()\n",
    "  print(lstm_v3_procedure_path_infos_key, accuracy_df.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 243,
     "status": "ok",
     "timestamp": 1738084417351,
     "user": {
      "displayName": "Furkan Ercelebi",
      "userId": "09395212391711469742"
     },
     "user_tz": -180
    },
    "id": "XdrHgpt-477C",
    "outputId": "ba28ab58-0d15-44de-f4bc-765c40d4d449"
   },
   "outputs": [],
   "source": [
    "LSTM_V4_LOG_DIRS = [sample_file for sample_file in sorted(Path(EXPR_PATH).iterdir(), key=os.path.getmtime) if sample_file.is_dir() and sample_file.name.startswith('LSTM_V4_Stress')]\n",
    "\n",
    "ignored_index_list = []\n",
    "# ignored_index_list = []\n",
    "\n",
    "lstm_v4_procedure_path_infos = {}\n",
    "\n",
    "for log_dir_idx in range(len(LSTM_V4_LOG_DIRS)):\n",
    "  if log_dir_idx not in ignored_index_list:\n",
    "\n",
    "    procedure_key = ''\n",
    "    sample_log_dir = LSTM_V4_LOG_DIRS[- log_dir_idx].name\n",
    "    if 'Non_Balance' in sample_log_dir:\n",
    "      procedure_key = 'NON_BLNC'\n",
    "    else:\n",
    "      procedure_key = 'BLNC'\n",
    "\n",
    "    if 'AP_1' in sample_log_dir and '__Seperated_Augmentation' in sample_log_dir:\n",
    "      procedure_key = f'{procedure_key}--ONL_ORG'\n",
    "    elif 'AP_ALL' in sample_log_dir and '__Seperated_Augmentation' in sample_log_dir:\n",
    "      procedure_key = f'{procedure_key}--ORG_AUG_SEP'\n",
    "    else:\n",
    "      procedure_key = f'{procedure_key}--ORG_AUG_MIX'\n",
    "\n",
    "    if 'FP_2' in sample_log_dir:\n",
    "      procedure_key = f'{procedure_key}--ALL'\n",
    "    else:\n",
    "      procedure_key = f'{procedure_key}--TD'\n",
    "\n",
    "    print(sample_log_dir, procedure_key)\n",
    "    lstm_v4_procedure_path_infos[procedure_key] = sample_log_dir\n",
    "\n",
    "\n",
    "print(lstm_v4_procedure_path_infos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 46434,
     "status": "ok",
     "timestamp": 1738084637503,
     "user": {
      "displayName": "Furkan Ercelebi",
      "userId": "09395212391711469742"
     },
     "user_tz": -180
    },
    "id": "ch0wyp0R6Bns",
    "outputId": "b6f80be5-13f7-4fb3-e84e-38111e2a4477"
   },
   "outputs": [],
   "source": [
    "\n",
    "lstm_v4_accuracy_df_infos = {}\n",
    "\n",
    "for lstm_v4_procedure_path_infos_key in lstm_v4_procedure_path_infos.keys():\n",
    "  kfold_logs_path = f'{EXPR_PATH}/{lstm_v4_procedure_path_infos[lstm_v4_procedure_path_infos_key]}/'\n",
    "\n",
    "  sample_files = [sample_file.name for sample_file in sorted(Path(kfold_logs_path).iterdir(), key=os.path.getmtime) if sample_file.is_dir() and sample_file.name.startswith('run')]\n",
    "\n",
    "  kfold_logs_path = os.path.join(kfold_logs_path, sample_files[-1])\n",
    "  for __ in range(4):\n",
    "    kfold_logs_path = os.path.join(kfold_logs_path, os.listdir(kfold_logs_path)[0])\n",
    "\n",
    "  accuracy_df = get_train_accuracy_values_as_df_from_log_path(kfold_logs_path)\n",
    "  lstm_v4_accuracy_df_infos[lstm_v4_procedure_path_infos_key] = accuracy_df.copy()\n",
    "  print(lstm_v4_procedure_path_infos_key, accuracy_df.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 211,
     "status": "ok",
     "timestamp": 1737847563029,
     "user": {
      "displayName": "Furkan Ercelebi",
      "userId": "09395212391711469742"
     },
     "user_tz": -180
    },
    "id": "1aBD-xndMzwn",
    "outputId": "0c69d7c8-dd63-4233-ba19-fce102a002fd"
   },
   "outputs": [],
   "source": [
    "ALEXNET_LOG_DIRS = [sample_file for sample_file in sorted(Path(EXPR_PATH).iterdir(), key=os.path.getmtime) if sample_file.is_dir() and sample_file.name.startswith('AlexNet')]\n",
    "\n",
    "ignored_index_list = [8, 14, 15]\n",
    "alexnet_procedure_path_infos = {}\n",
    "\n",
    "for log_dir_idx in range(1, 16):\n",
    "  if log_dir_idx not in ignored_index_list:\n",
    "\n",
    "    procedure_key = ''\n",
    "    sample_log_dir = ALEXNET_LOG_DIRS[- log_dir_idx].name\n",
    "    if 'Non_Balance' in sample_log_dir:\n",
    "      procedure_key = 'NON_BLNC'\n",
    "    else:\n",
    "      procedure_key = 'BLNC'\n",
    "\n",
    "    if 'AP_1' in sample_log_dir and '__Seperated_Augmentation' in sample_log_dir:\n",
    "      procedure_key = f'{procedure_key}--ONL_ORG'\n",
    "    elif 'AP_ALL' in sample_log_dir and '__Seperated_Augmentation' in sample_log_dir:\n",
    "      procedure_key = f'{procedure_key}--ORG_AUG_SEP'\n",
    "    else:\n",
    "      procedure_key = f'{procedure_key}--ORG_AUG_MIX'\n",
    "\n",
    "    if 'FP_2' in sample_log_dir:\n",
    "      procedure_key = f'{procedure_key}--ALL'\n",
    "    else:\n",
    "      procedure_key = f'{procedure_key}--TD'\n",
    "\n",
    "    print(sample_log_dir, procedure_key)\n",
    "    alexnet_procedure_path_infos[procedure_key] = sample_log_dir\n",
    "\n",
    "\n",
    "print(alexnet_procedure_path_infos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wBfKMJEHyZk5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27219,
     "status": "ok",
     "timestamp": 1737848938243,
     "user": {
      "displayName": "Furkan Ercelebi",
      "userId": "09395212391711469742"
     },
     "user_tz": -180
    },
    "id": "bbokvnjWyZtQ",
    "outputId": "7682dbbb-c978-4958-b1af-5c8ce92af710"
   },
   "outputs": [],
   "source": [
    "\n",
    "alexnet_accuracy_df_infos = {}\n",
    "\n",
    "for alexnet_procedure_path_infos_key in alexnet_procedure_path_infos.keys():\n",
    "  kfold_logs_path = f'{EXPR_PATH}/{alexnet_procedure_path_infos[alexnet_procedure_path_infos_key]}/'\n",
    "\n",
    "  sample_files = [sample_file.name for sample_file in sorted(Path(kfold_logs_path).iterdir(), key=os.path.getmtime) if sample_file.is_dir() and sample_file.name.startswith('run')]\n",
    "\n",
    "  kfold_logs_path = os.path.join(kfold_logs_path, sample_files[-1])\n",
    "  for __ in range(4):\n",
    "    kfold_logs_path = os.path.join(kfold_logs_path, os.listdir(kfold_logs_path)[0])\n",
    "\n",
    "  accuracy_df = get_train_accuracy_values_as_df_from_log_path(kfold_logs_path)\n",
    "  alexnet_accuracy_df_infos[alexnet_procedure_path_infos_key] = accuracy_df.copy()\n",
    "  print(alexnet_procedure_path_infos_key, accuracy_df.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 9697,
     "status": "ok",
     "timestamp": 1737849825028,
     "user": {
      "displayName": "Furkan Ercelebi",
      "userId": "09395212391711469742"
     },
     "user_tz": -180
    },
    "id": "HkfjgznVzYXP",
    "outputId": "e153e33f-15ec-4ae1-e579-2bc5bfdd17b5"
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(6, 6, figsize=(30, 30))\n",
    "\n",
    "procedure_list = ['BLNC--ONL_ORG', \\\n",
    "                  'NON_BLNC--ONL_ORG', \\\n",
    "                  'BLNC--ORG_AUG_SEP',\\\n",
    "                  'NON_BLNC--ORG_AUG_SEP',\\\n",
    "                  'BLNC--ORG_AUG_MIX', \\\n",
    "                  'NON_BLNC--ORG_AUG_MIX']\n",
    "\n",
    "axes_idx = 0\n",
    "\n",
    "for row_idx in range(6):\n",
    "\n",
    "  main_log_df = alexnet_accuracy_df_infos[f'{procedure_list[row_idx]}--ALL'].copy()\n",
    "\n",
    "  sns.lineplot(data=main_log_df, x='Epoch', y='Ratio', hue=\"Phase\", ax=axes[row_idx][0])\n",
    "\n",
    "  procedure_components = procedure_list[row_idx].split('--')\n",
    "  axes[row_idx][0].set_title(f'AlexNet {procedure_components[0]}, {procedure_components[1]}, ALL')\n",
    "  axes_idx += 1\n",
    "\n",
    "  main_log_df = alexnet_accuracy_df_infos[f'{procedure_list[row_idx]}--TD'].copy()\n",
    "\n",
    "  sns.lineplot(data=main_log_df, x='Epoch', y='Ratio', hue=\"Phase\", ax=axes[row_idx][1])\n",
    "\n",
    "  procedure_components = procedure_list[row_idx].split('--')\n",
    "  axes[row_idx][1].set_title(f'AlexNet {procedure_components[0]}, {procedure_components[1]}, TD')\n",
    "  axes_idx += 1\n",
    "\n",
    "\n",
    "  main_log_df = lstm_accuracy_df_infos[f'{procedure_list[row_idx]}--ALL'].copy()\n",
    "\n",
    "  sns.lineplot(data=main_log_df, x='Epoch', y='Ratio', hue=\"Phase\", ax=axes[row_idx][2])\n",
    "\n",
    "  procedure_components = procedure_list[row_idx].split('--')\n",
    "  axes[row_idx][2].set_title(f'LSTM {procedure_components[0]}, {procedure_components[1]}, ALL')\n",
    "  axes_idx += 1\n",
    "\n",
    "  main_log_df = lstm_accuracy_df_infos[f'{procedure_list[row_idx]}--TD'].copy()\n",
    "\n",
    "  sns.lineplot(data=main_log_df, x='Epoch', y='Ratio', hue=\"Phase\", ax=axes[row_idx][3])\n",
    "\n",
    "  procedure_components = procedure_list[row_idx].split('--')\n",
    "  axes[row_idx][3].set_title(f'LSTM {procedure_components[0]}, {procedure_components[1]}, TD')\n",
    "  axes_idx += 1\n",
    "\n",
    "\n",
    "  main_log_df = lstm_v2_accuracy_df_infos[f'{procedure_list[row_idx]}--ALL'].copy()\n",
    "\n",
    "  sns.lineplot(data=main_log_df, x='Epoch', y='Ratio', hue=\"Phase\", ax=axes[row_idx][4])\n",
    "\n",
    "  procedure_components = procedure_list[row_idx].split('--')\n",
    "  axes[row_idx][4].set_title(f'LSTM V2 {procedure_components[0]}, {procedure_components[1]}, ALL')\n",
    "  axes_idx += 1\n",
    "\n",
    "  main_log_df = lstm_v2_accuracy_df_infos[f'{procedure_list[row_idx]}--TD'].copy()\n",
    "\n",
    "  sns.lineplot(data=main_log_df, x='Epoch', y='Ratio', hue=\"Phase\", ax=axes[row_idx][5])\n",
    "\n",
    "  procedure_components = procedure_list[row_idx].split('--')\n",
    "  axes[row_idx][5].set_title(f'LSTM V2 {procedure_components[0]}, {procedure_components[1]}, TD')\n",
    "  axes_idx += 1\n",
    "\n",
    "\n",
    "# Adjust the spacing between plots\n",
    "plt.tight_layout()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n",
    "\n",
    "# fig.savefig(f\"{model_name}_{experiment_procedure_name}_{(i + 1)}KFold.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 7167,
     "status": "ok",
     "timestamp": 1738085936094,
     "user": {
      "displayName": "Furkan Ercelebi",
      "userId": "09395212391711469742"
     },
     "user_tz": -180
    },
    "id": "5ju0GGRA6l-3",
    "outputId": "c22632b8-d680-4bc8-88ee-993c7416adcb"
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(6, 2, figsize=(30, 30))\n",
    "\n",
    "procedure_list = ['BLNC--ONL_ORG--ALL', \\\n",
    "                  'BLNC--ORG_AUG_SEP--ALL',\\\n",
    "                  'NON_BLNC--ORG_AUG_SEP--ALL',\\\n",
    "                  'BLNC--ORG_AUG_MIX--ALL', \\\n",
    "                  'NON_BLNC--ORG_AUG_MIX--ALL']\n",
    "\n",
    "for row_idx in range(6):\n",
    "\n",
    "  axes_idx = 0\n",
    "  if row_idx < 5:\n",
    "\n",
    "    main_log_df = lstm_v3_accuracy_df_infos[f'{procedure_list[row_idx]}--NON_RAW'].copy()\n",
    "\n",
    "    sns.lineplot(data=main_log_df, x='Epoch', y='Ratio', hue=\"Phase\", ax=axes[row_idx][axes_idx])\n",
    "\n",
    "    procedure_components = procedure_list[row_idx].split('--')\n",
    "    axes[row_idx][axes_idx].set_title(f'LSTM V3 {procedure_components[0]}, {procedure_components[1]}, {procedure_components[2]}')\n",
    "    axes_idx += 1\n",
    "\n",
    "    main_log_df = lstm_v4_accuracy_df_infos[procedure_list[row_idx]].copy()\n",
    "\n",
    "    sns.lineplot(data=main_log_df, x='Epoch', y='Ratio', hue=\"Phase\", ax=axes[row_idx][axes_idx])\n",
    "\n",
    "    procedure_components = procedure_list[row_idx].split('--')\n",
    "    axes[row_idx][axes_idx].set_title(f'LSTM V4 {procedure_components[0]}, {procedure_components[1]}, {procedure_components[2]}')\n",
    "    axes_idx += 1\n",
    "\n",
    "  else:\n",
    "\n",
    "    main_log_df = lstm_v3_accuracy_df_infos[f'{procedure_list[3]}--RAW'].copy()\n",
    "\n",
    "    sns.lineplot(data=main_log_df, x='Epoch', y='Ratio', hue=\"Phase\", ax=axes[row_idx][axes_idx])\n",
    "\n",
    "    procedure_components = procedure_list[3].split('--')\n",
    "    axes[row_idx][axes_idx].set_title(f'LSTM V3 {procedure_components[0]}, {procedure_components[1]}, {procedure_components[2]}, RAW')\n",
    "    axes_idx += 1\n",
    "\n",
    "\n",
    "# Adjust the spacing between plots\n",
    "plt.tight_layout()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n",
    "\n",
    "# fig.savefig(f\"{model_name}_{experiment_procedure_name}_{(i + 1)}KFold.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nP40kpvE7Voc"
   },
   "outputs": [],
   "source": [
    "def get_train_loss_values_as_df_from_log_path(log_path):\n",
    "\n",
    "  mean_loss_train = []\n",
    "  mean_loss_val = []\n",
    "\n",
    "  kfold_range = int((len(os.listdir(log_path)) - 1) / 5)\n",
    "\n",
    "  for i in range(kfold_range):\n",
    "\n",
    "    log_dir = f'{log_path}/Loss - {(i + 1)}_val/loss'\n",
    "    ratio_values = tflog2pandas(os.path.join(log_dir, os.listdir(log_dir)[0]), f'Loss - {(i + 1)}')\n",
    "    if i > 0:\n",
    "      if len(mean_loss_val[0]) == len(ratio_values):\n",
    "        mean_loss_val.append(list(ratio_values))\n",
    "    else:\n",
    "      mean_loss_val.append(list(ratio_values))\n",
    "\n",
    "    log_dir = f'{log_path}/Loss - {(i + 1)}_train/loss'\n",
    "    ratio_values = tflog2pandas(os.path.join(log_dir, os.listdir(log_dir)[0]), f'Loss - {(i + 1)}')\n",
    "    if i > 0:\n",
    "      if len(mean_loss_val[0]) == len(ratio_values):\n",
    "        mean_loss_train.append(list(ratio_values))\n",
    "    else:\n",
    "      mean_loss_train.append(list(ratio_values))\n",
    "\n",
    "\n",
    "  main_log_df = pd.DataFrame()\n",
    "\n",
    "  log_df = pd.DataFrame()\n",
    "  log_df['Ratio'] = np.mean(mean_loss_val, axis=0)\n",
    "  log_df['Phase'] = ['Validation' for ratio_idx in range(len(log_df['Ratio']))]\n",
    "  log_df['Epoch'] = [epoch_idx + 1 for epoch_idx in range(len(log_df['Ratio']))]\n",
    "  main_log_df = pd.concat([main_log_df, log_df])\n",
    "\n",
    "  log_df = pd.DataFrame()\n",
    "  log_df['Ratio'] = np.mean(mean_loss_train, axis=0)\n",
    "  log_df['Phase'] = ['Train' for ratio_idx in range(len(log_df['Ratio']))]\n",
    "  log_df['Epoch'] = [epoch_idx + 1 for epoch_idx in range(len(log_df['Ratio']))]\n",
    "  main_log_df = pd.concat([main_log_df, log_df])\n",
    "\n",
    "  return main_log_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 166441,
     "status": "ok",
     "timestamp": 1737852976085,
     "user": {
      "displayName": "Furkan Ercelebi",
      "userId": "09395212391711469742"
     },
     "user_tz": -180
    },
    "id": "7QLkvOnpFvJA",
    "outputId": "72882242-4412-4b7a-fe08-46fcada57932"
   },
   "outputs": [],
   "source": [
    "\n",
    "lstm_loss_df_infos = {}\n",
    "\n",
    "for lstm_procedure_path_infos_key in lstm_procedure_path_infos.keys():\n",
    "  kfold_logs_path = f'{EXPR_PATH}/{lstm_procedure_path_infos[lstm_procedure_path_infos_key]}/'\n",
    "\n",
    "  sample_files = [sample_file.name for sample_file in sorted(Path(kfold_logs_path).iterdir(), key=os.path.getmtime) if sample_file.is_dir() and sample_file.name.startswith('run')]\n",
    "\n",
    "  kfold_logs_path = os.path.join(kfold_logs_path, sample_files[-1])\n",
    "  for __ in range(4):\n",
    "    kfold_logs_path = os.path.join(kfold_logs_path, os.listdir(kfold_logs_path)[0])\n",
    "\n",
    "  loss_df = get_train_loss_values_as_df_from_log_path(kfold_logs_path)\n",
    "  lstm_loss_df_infos[lstm_procedure_path_infos_key] = loss_df.copy()\n",
    "  print(lstm_procedure_path_infos_key, loss_df.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "lstm_v2_loss_df_infos = {}\n",
    "\n",
    "for lstm_v2_procedure_path_infos_key in lstm_v2_procedure_path_infos.keys():\n",
    "  kfold_logs_path = f'{EXPR_PATH}/{lstm_v2_procedure_path_infos[lstm_v2_procedure_path_infos_key]}/'\n",
    "\n",
    "  sample_files = [sample_file.name for sample_file in sorted(Path(kfold_logs_path).iterdir(), key=os.path.getmtime) if sample_file.is_dir() and sample_file.name.startswith('run')]\n",
    "\n",
    "  kfold_logs_path = os.path.join(kfold_logs_path, sample_files[-1])\n",
    "  for __ in range(4):\n",
    "    kfold_logs_path = os.path.join(kfold_logs_path, os.listdir(kfold_logs_path)[0])\n",
    "\n",
    "  loss_df = get_train_loss_values_as_df_from_log_path(kfold_logs_path)\n",
    "  lstm_v2_loss_df_infos[lstm_v2_procedure_path_infos_key] = loss_df.copy()\n",
    "  print(lstm_v2_procedure_path_infos_key, loss_df.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "alexnet_loss_df_infos = {}\n",
    "\n",
    "for alexnet_procedure_path_infos_key in alexnet_procedure_path_infos.keys():\n",
    "  kfold_logs_path = f'{EXPR_PATH}/{alexnet_procedure_path_infos[alexnet_procedure_path_infos_key]}/'\n",
    "\n",
    "  sample_files = [sample_file.name for sample_file in sorted(Path(kfold_logs_path).iterdir(), key=os.path.getmtime) if sample_file.is_dir() and sample_file.name.startswith('run')]\n",
    "\n",
    "  kfold_logs_path = os.path.join(kfold_logs_path, sample_files[-1])\n",
    "  for __ in range(4):\n",
    "    kfold_logs_path = os.path.join(kfold_logs_path, os.listdir(kfold_logs_path)[0])\n",
    "\n",
    "  loss_df = get_train_loss_values_as_df_from_log_path(kfold_logs_path)\n",
    "  alexnet_loss_df_infos[alexnet_procedure_path_infos_key] = loss_df.copy()\n",
    "  print(alexnet_procedure_path_infos_key, loss_df.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 8829,
     "status": "ok",
     "timestamp": 1737853048924,
     "user": {
      "displayName": "Furkan Ercelebi",
      "userId": "09395212391711469742"
     },
     "user_tz": -180
    },
    "id": "QEyxnW4DGa7r",
    "outputId": "cd4c7317-29fb-4155-8313-a9f53aae1176"
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(6, 6, figsize=(30, 30))\n",
    "\n",
    "procedure_list = ['BLNC--ONL_ORG', \\\n",
    "                  'NON_BLNC--ONL_ORG', \\\n",
    "                  'BLNC--ORG_AUG_SEP',\\\n",
    "                  'NON_BLNC--ORG_AUG_SEP',\\\n",
    "                  'BLNC--ORG_AUG_MIX', \\\n",
    "                  'NON_BLNC--ORG_AUG_MIX']\n",
    "\n",
    "axes_idx = 0\n",
    "\n",
    "for row_idx in range(6):\n",
    "\n",
    "  main_log_df = alexnet_loss_df_infos[f'{procedure_list[row_idx]}--ALL'].copy()\n",
    "\n",
    "  sns.lineplot(data=main_log_df, x='Epoch', y='Ratio', hue=\"Phase\", ax=axes[row_idx][0])\n",
    "\n",
    "  procedure_components = procedure_list[row_idx].split('--')\n",
    "  axes[row_idx][0].set_title(f'AlexNet {procedure_components[0]}, {procedure_components[1]}, ALL')\n",
    "  axes_idx += 1\n",
    "\n",
    "  main_log_df = alexnet_loss_df_infos[f'{procedure_list[row_idx]}--TD'].copy()\n",
    "\n",
    "  sns.lineplot(data=main_log_df, x='Epoch', y='Ratio', hue=\"Phase\", ax=axes[row_idx][1])\n",
    "\n",
    "  procedure_components = procedure_list[row_idx].split('--')\n",
    "  axes[row_idx][1].set_title(f'AlexNet {procedure_components[0]}, {procedure_components[1]}, TD')\n",
    "  axes_idx += 1\n",
    "\n",
    "\n",
    "  main_log_df = lstm_loss_df_infos[f'{procedure_list[row_idx]}--ALL'].copy()\n",
    "\n",
    "  sns.lineplot(data=main_log_df, x='Epoch', y='Ratio', hue=\"Phase\", ax=axes[row_idx][2])\n",
    "\n",
    "  procedure_components = procedure_list[row_idx].split('--')\n",
    "  axes[row_idx][2].set_title(f'LSTM {procedure_components[0]}, {procedure_components[1]}, ALL')\n",
    "  axes_idx += 1\n",
    "\n",
    "  main_log_df = lstm_loss_df_infos[f'{procedure_list[row_idx]}--TD'].copy()\n",
    "\n",
    "  sns.lineplot(data=main_log_df, x='Epoch', y='Ratio', hue=\"Phase\", ax=axes[row_idx][3])\n",
    "\n",
    "  procedure_components = procedure_list[row_idx].split('--')\n",
    "  axes[row_idx][3].set_title(f'LSTM {procedure_components[0]}, {procedure_components[1]}, TD')\n",
    "  axes_idx += 1\n",
    "\n",
    "\n",
    "  main_log_df = lstm_v2_loss_df_infos[f'{procedure_list[row_idx]}--ALL'].copy()\n",
    "\n",
    "  sns.lineplot(data=main_log_df, x='Epoch', y='Ratio', hue=\"Phase\", ax=axes[row_idx][4])\n",
    "\n",
    "  procedure_components = procedure_list[row_idx].split('--')\n",
    "  axes[row_idx][4].set_title(f'LSTM V2 {procedure_components[0]}, {procedure_components[1]}, ALL')\n",
    "  axes_idx += 1\n",
    "\n",
    "  main_log_df = lstm_v2_loss_df_infos[f'{procedure_list[row_idx]}--TD'].copy()\n",
    "\n",
    "  sns.lineplot(data=main_log_df, x='Epoch', y='Ratio', hue=\"Phase\", ax=axes[row_idx][5])\n",
    "\n",
    "  procedure_components = procedure_list[row_idx].split('--')\n",
    "  axes[row_idx][5].set_title(f'LSTM V2 {procedure_components[0]}, {procedure_components[1]}, TD')\n",
    "  axes_idx += 1\n",
    "\n",
    "\n",
    "# Adjust the spacing between plots\n",
    "plt.tight_layout()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n",
    "\n",
    "# fig.savefig(f\"{model_name}_{experiment_procedure_name}_{(i + 1)}KFold.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 68021,
     "status": "ok",
     "timestamp": 1738086238441,
     "user": {
      "displayName": "Furkan Ercelebi",
      "userId": "09395212391711469742"
     },
     "user_tz": -180
    },
    "id": "u9yO96DqAVcV",
    "outputId": "e01d44ea-d9ce-420f-d391-d63986c56c4a"
   },
   "outputs": [],
   "source": [
    "\n",
    "lstm_v3_loss_df_infos = {}\n",
    "\n",
    "for lstm_v3_procedure_path_infos_key in lstm_v3_procedure_path_infos.keys():\n",
    "  kfold_logs_path = f'{EXPR_PATH}/{lstm_v3_procedure_path_infos[lstm_v3_procedure_path_infos_key]}/'\n",
    "\n",
    "  sample_files = [sample_file.name for sample_file in sorted(Path(kfold_logs_path).iterdir(), key=os.path.getmtime) if sample_file.is_dir() and sample_file.name.startswith('run')]\n",
    "\n",
    "  kfold_logs_path = os.path.join(kfold_logs_path, sample_files[-1])\n",
    "  for __ in range(4):\n",
    "    kfold_logs_path = os.path.join(kfold_logs_path, os.listdir(kfold_logs_path)[0])\n",
    "\n",
    "  loss_df = get_train_loss_values_as_df_from_log_path(kfold_logs_path)\n",
    "  lstm_v3_loss_df_infos[lstm_v3_procedure_path_infos_key] = loss_df.copy()\n",
    "  print(lstm_v3_procedure_path_infos_key, loss_df.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "lstm_v4_loss_df_infos = {}\n",
    "\n",
    "for lstm_v4_procedure_path_infos_key in lstm_v4_procedure_path_infos.keys():\n",
    "  kfold_logs_path = f'{EXPR_PATH}/{lstm_v4_procedure_path_infos[lstm_v4_procedure_path_infos_key]}/'\n",
    "\n",
    "  sample_files = [sample_file.name for sample_file in sorted(Path(kfold_logs_path).iterdir(), key=os.path.getmtime) if sample_file.is_dir() and sample_file.name.startswith('run')]\n",
    "\n",
    "  kfold_logs_path = os.path.join(kfold_logs_path, sample_files[-1])\n",
    "  for __ in range(4):\n",
    "    kfold_logs_path = os.path.join(kfold_logs_path, os.listdir(kfold_logs_path)[0])\n",
    "\n",
    "  loss_df = get_train_loss_values_as_df_from_log_path(kfold_logs_path)\n",
    "  lstm_v4_loss_df_infos[lstm_v4_procedure_path_infos_key] = loss_df.copy()\n",
    "  print(lstm_v4_procedure_path_infos_key, loss_df.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 5046,
     "status": "ok",
     "timestamp": 1738086243481,
     "user": {
      "displayName": "Furkan Ercelebi",
      "userId": "09395212391711469742"
     },
     "user_tz": -180
    },
    "id": "egLy3rKmAVcW",
    "outputId": "79676e27-d8fd-4e66-ad0d-ba02c974a291"
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(6, 2, figsize=(30, 30))\n",
    "\n",
    "procedure_list = ['BLNC--ONL_ORG--ALL', \\\n",
    "                  'BLNC--ORG_AUG_SEP--ALL',\\\n",
    "                  'NON_BLNC--ORG_AUG_SEP--ALL',\\\n",
    "                  'BLNC--ORG_AUG_MIX--ALL', \\\n",
    "                  'NON_BLNC--ORG_AUG_MIX--ALL']\n",
    "\n",
    "for row_idx in range(6):\n",
    "\n",
    "  axes_idx = 0\n",
    "  if row_idx < 5:\n",
    "\n",
    "    main_log_df = lstm_v3_loss_df_infos[f'{procedure_list[row_idx]}--NON_RAW'].copy()\n",
    "\n",
    "    sns.lineplot(data=main_log_df, x='Epoch', y='Ratio', hue=\"Phase\", ax=axes[row_idx][axes_idx])\n",
    "\n",
    "    procedure_components = procedure_list[row_idx].split('--')\n",
    "    axes[row_idx][axes_idx].set_title(f'LSTM V3 {procedure_components[0]}, {procedure_components[1]}, {procedure_components[2]}')\n",
    "    axes_idx += 1\n",
    "\n",
    "    main_log_df = lstm_v4_loss_df_infos[procedure_list[row_idx]].copy()\n",
    "\n",
    "    sns.lineplot(data=main_log_df, x='Epoch', y='Ratio', hue=\"Phase\", ax=axes[row_idx][axes_idx])\n",
    "\n",
    "    procedure_components = procedure_list[row_idx].split('--')\n",
    "    axes[row_idx][axes_idx].set_title(f'LSTM V4 {procedure_components[0]}, {procedure_components[1]}, {procedure_components[2]}')\n",
    "    axes_idx += 1\n",
    "\n",
    "  else:\n",
    "\n",
    "    main_log_df = lstm_v3_loss_df_infos[f'{procedure_list[3]}--RAW'].copy()\n",
    "\n",
    "    sns.lineplot(data=main_log_df, x='Epoch', y='Ratio', hue=\"Phase\", ax=axes[row_idx][axes_idx])\n",
    "\n",
    "    procedure_components = procedure_list[3].split('--')\n",
    "    axes[row_idx][axes_idx].set_title(f'LSTM V3 {procedure_components[0]}, {procedure_components[1]}, {procedure_components[2]}, RAW')\n",
    "    axes_idx += 1\n",
    "\n",
    "\n",
    "# Adjust the spacing between plots\n",
    "plt.tight_layout()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n",
    "\n",
    "# fig.savefig(f\"{model_name}_{experiment_procedure_name}_{(i + 1)}KFold.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1ALVJLLS7WAR"
   },
   "outputs": [],
   "source": [
    "def get_train_other_values_as_df_from_log_path(log_path):\n",
    "\n",
    "  kfold_range = int((len(os.listdir(log_path)) - 1) / 5)\n",
    "  main_log_df = pd.DataFrame()\n",
    "\n",
    "  mean_f1score_val = []\n",
    "  for i in range(kfold_range):\n",
    "\n",
    "    log_dir = f'{log_path}/Others - {(i + 1)}_val/f1score'\n",
    "    ratio_values = tflog2pandas(os.path.join(log_dir, os.listdir(log_dir)[0]), f'Others - {(i + 1)}')\n",
    "    if i > 0:\n",
    "      if len(mean_f1score_val[0]) == len(ratio_values):\n",
    "        mean_f1score_val.append(list(ratio_values))\n",
    "    else:\n",
    "      mean_f1score_val.append(list(ratio_values))\n",
    "\n",
    "  log_df = pd.DataFrame()\n",
    "  log_df['Ratio'] = np.mean(mean_f1score_val, axis=0)\n",
    "  log_df['Phase'] = ['F1 Score' for ratio_idx in range(len(log_df['Ratio']))]\n",
    "  log_df['Epoch'] = [epoch_idx + 1 for epoch_idx in range(len(log_df['Ratio']))]\n",
    "  main_log_df = pd.concat([main_log_df, log_df])\n",
    "\n",
    "\n",
    "  mean_precision_val = []\n",
    "  for i in range(kfold_range):\n",
    "\n",
    "    log_dir = f'{log_path}/Others - {(i + 1)}_val/precision'\n",
    "    ratio_values = tflog2pandas(os.path.join(log_dir, os.listdir(log_dir)[0]), f'Others - {(i + 1)}')\n",
    "    if i > 0:\n",
    "      if len(mean_precision_val[0]) == len(ratio_values):\n",
    "        mean_precision_val.append(list(ratio_values))\n",
    "    else:\n",
    "      mean_precision_val.append(list(ratio_values))\n",
    "\n",
    "  log_df = pd.DataFrame()\n",
    "  log_df['Ratio'] = np.mean(mean_precision_val, axis=0)\n",
    "  log_df['Phase'] = ['Precision' for ratio_idx in range(len(log_df['Ratio']))]\n",
    "  log_df['Epoch'] = [epoch_idx + 1 for epoch_idx in range(len(log_df['Ratio']))]\n",
    "  main_log_df = pd.concat([main_log_df, log_df])\n",
    "\n",
    "\n",
    "  mean_recall_val = []\n",
    "  for i in range(kfold_range):\n",
    "\n",
    "    log_dir = f'{log_path}/Others - {(i + 1)}_val/recall'\n",
    "    ratio_values = tflog2pandas(os.path.join(log_dir, os.listdir(log_dir)[0]), f'Others - {(i + 1)}')\n",
    "    if i > 0:\n",
    "      if len(mean_f1score_val[0]) == len(ratio_values):\n",
    "        mean_f1score_val.append(list(ratio_values))\n",
    "    else:\n",
    "      mean_f1score_val.append(list(ratio_values))\n",
    "\n",
    "  log_df = pd.DataFrame()\n",
    "  log_df['Ratio'] = np.mean(mean_f1score_val, axis=0)\n",
    "  log_df['Phase'] = ['Recall' for ratio_idx in range(len(log_df['Ratio']))]\n",
    "  log_df['Epoch'] = [epoch_idx + 1 for epoch_idx in range(len(log_df['Ratio']))]\n",
    "  main_log_df = pd.concat([main_log_df, log_df])\n",
    "\n",
    "\n",
    "  return main_log_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 234015,
     "status": "ok",
     "timestamp": 1737853543050,
     "user": {
      "displayName": "Furkan Ercelebi",
      "userId": "09395212391711469742"
     },
     "user_tz": -180
    },
    "id": "qPKC1JgrHjip",
    "outputId": "81f612e5-b5fe-4664-ceea-d920b03f56dc"
   },
   "outputs": [],
   "source": [
    "\n",
    "lstm_other_df_infos = {}\n",
    "\n",
    "for lstm_procedure_path_infos_key in lstm_procedure_path_infos.keys():\n",
    "  kfold_logs_path = f'{EXPR_PATH}/{lstm_procedure_path_infos[lstm_procedure_path_infos_key]}/'\n",
    "\n",
    "  sample_files = [sample_file.name for sample_file in sorted(Path(kfold_logs_path).iterdir(), key=os.path.getmtime) if sample_file.is_dir() and sample_file.name.startswith('run')]\n",
    "\n",
    "  kfold_logs_path = os.path.join(kfold_logs_path, sample_files[-1])\n",
    "  for __ in range(4):\n",
    "    kfold_logs_path = os.path.join(kfold_logs_path, os.listdir(kfold_logs_path)[0])\n",
    "\n",
    "  other_df = get_train_other_values_as_df_from_log_path(kfold_logs_path)\n",
    "  lstm_other_df_infos[lstm_procedure_path_infos_key] = other_df.copy()\n",
    "  print(lstm_procedure_path_infos_key, other_df.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "lstm_v2_other_df_infos = {}\n",
    "\n",
    "for lstm_v2_procedure_path_infos_key in lstm_v2_procedure_path_infos.keys():\n",
    "  kfold_logs_path = f'{EXPR_PATH}/{lstm_v2_procedure_path_infos[lstm_v2_procedure_path_infos_key]}/'\n",
    "\n",
    "  sample_files = [sample_file.name for sample_file in sorted(Path(kfold_logs_path).iterdir(), key=os.path.getmtime) if sample_file.is_dir() and sample_file.name.startswith('run')]\n",
    "\n",
    "  kfold_logs_path = os.path.join(kfold_logs_path, sample_files[-1])\n",
    "  for __ in range(4):\n",
    "    kfold_logs_path = os.path.join(kfold_logs_path, os.listdir(kfold_logs_path)[0])\n",
    "\n",
    "  other_df = get_train_other_values_as_df_from_log_path(kfold_logs_path)\n",
    "  lstm_v2_other_df_infos[lstm_v2_procedure_path_infos_key] = other_df.copy()\n",
    "  print(lstm_v2_procedure_path_infos_key, other_df.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "alexnet_other_df_infos = {}\n",
    "\n",
    "for alexnet_procedure_path_infos_key in alexnet_procedure_path_infos.keys():\n",
    "  kfold_logs_path = f'{EXPR_PATH}/{alexnet_procedure_path_infos[alexnet_procedure_path_infos_key]}/'\n",
    "\n",
    "  sample_files = [sample_file.name for sample_file in sorted(Path(kfold_logs_path).iterdir(), key=os.path.getmtime) if sample_file.is_dir() and sample_file.name.startswith('run')]\n",
    "\n",
    "  kfold_logs_path = os.path.join(kfold_logs_path, sample_files[-1])\n",
    "  for __ in range(4):\n",
    "    kfold_logs_path = os.path.join(kfold_logs_path, os.listdir(kfold_logs_path)[0])\n",
    "\n",
    "  other_df = get_train_other_values_as_df_from_log_path(kfold_logs_path)\n",
    "  alexnet_other_df_infos[alexnet_procedure_path_infos_key] = other_df.copy()\n",
    "  print(alexnet_procedure_path_infos_key, other_df.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 11631,
     "status": "ok",
     "timestamp": 1737853573454,
     "user": {
      "displayName": "Furkan Ercelebi",
      "userId": "09395212391711469742"
     },
     "user_tz": -180
    },
    "id": "0TWjwvwsHjiq",
    "outputId": "c3e0b843-9826-4ac8-e440-e2e5cb6e44d5"
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(6, 6, figsize=(30, 30))\n",
    "\n",
    "procedure_list = ['BLNC--ONL_ORG', \\\n",
    "                  'NON_BLNC--ONL_ORG', \\\n",
    "                  'BLNC--ORG_AUG_SEP',\\\n",
    "                  'NON_BLNC--ORG_AUG_SEP',\\\n",
    "                  'BLNC--ORG_AUG_MIX', \\\n",
    "                  'NON_BLNC--ORG_AUG_MIX']\n",
    "\n",
    "axes_idx = 0\n",
    "\n",
    "for row_idx in range(6):\n",
    "\n",
    "  main_log_df = alexnet_other_df_infos[f'{procedure_list[row_idx]}--ALL'].copy()\n",
    "\n",
    "  sns.lineplot(data=main_log_df, x='Epoch', y='Ratio', hue=\"Phase\", ax=axes[row_idx][0])\n",
    "\n",
    "  procedure_components = procedure_list[row_idx].split('--')\n",
    "  axes[row_idx][0].set_title(f'AlexNet {procedure_components[0]}, {procedure_components[1]}, ALL')\n",
    "  axes_idx += 1\n",
    "\n",
    "  main_log_df = alexnet_other_df_infos[f'{procedure_list[row_idx]}--TD'].copy()\n",
    "\n",
    "  sns.lineplot(data=main_log_df, x='Epoch', y='Ratio', hue=\"Phase\", ax=axes[row_idx][1])\n",
    "\n",
    "  procedure_components = procedure_list[row_idx].split('--')\n",
    "  axes[row_idx][1].set_title(f'AlexNet {procedure_components[0]}, {procedure_components[1]}, TD')\n",
    "  axes_idx += 1\n",
    "\n",
    "\n",
    "  main_log_df = lstm_other_df_infos[f'{procedure_list[row_idx]}--ALL'].copy()\n",
    "\n",
    "  sns.lineplot(data=main_log_df, x='Epoch', y='Ratio', hue=\"Phase\", ax=axes[row_idx][2])\n",
    "\n",
    "  procedure_components = procedure_list[row_idx].split('--')\n",
    "  axes[row_idx][2].set_title(f'LSTM {procedure_components[0]}, {procedure_components[1]}, ALL')\n",
    "  axes_idx += 1\n",
    "\n",
    "  main_log_df = lstm_other_df_infos[f'{procedure_list[row_idx]}--TD'].copy()\n",
    "\n",
    "  sns.lineplot(data=main_log_df, x='Epoch', y='Ratio', hue=\"Phase\", ax=axes[row_idx][3])\n",
    "\n",
    "  procedure_components = procedure_list[row_idx].split('--')\n",
    "  axes[row_idx][3].set_title(f'LSTM {procedure_components[0]}, {procedure_components[1]}, TD')\n",
    "  axes_idx += 1\n",
    "\n",
    "\n",
    "  main_log_df = lstm_v2_other_df_infos[f'{procedure_list[row_idx]}--ALL'].copy()\n",
    "\n",
    "  sns.lineplot(data=main_log_df, x='Epoch', y='Ratio', hue=\"Phase\", ax=axes[row_idx][4])\n",
    "\n",
    "  procedure_components = procedure_list[row_idx].split('--')\n",
    "  axes[row_idx][4].set_title(f'LSTM V2 {procedure_components[0]}, {procedure_components[1]}, ALL')\n",
    "  axes_idx += 1\n",
    "\n",
    "  main_log_df = lstm_v2_other_df_infos[f'{procedure_list[row_idx]}--TD'].copy()\n",
    "\n",
    "  sns.lineplot(data=main_log_df, x='Epoch', y='Ratio', hue=\"Phase\", ax=axes[row_idx][5])\n",
    "\n",
    "  procedure_components = procedure_list[row_idx].split('--')\n",
    "  axes[row_idx][5].set_title(f'LSTM V2 {procedure_components[0]}, {procedure_components[1]}, TD')\n",
    "  axes_idx += 1\n",
    "\n",
    "\n",
    "# Adjust the spacing between plots\n",
    "plt.tight_layout()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n",
    "\n",
    "# fig.savefig(f\"{model_name}_{experiment_procedure_name}_{(i + 1)}KFold.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 99598,
     "status": "ok",
     "timestamp": 1738086411144,
     "user": {
      "displayName": "Furkan Ercelebi",
      "userId": "09395212391711469742"
     },
     "user_tz": -180
    },
    "id": "ApktFhxnA8-k",
    "outputId": "c4a7917b-d42a-4a1d-e0a3-730165e8724b"
   },
   "outputs": [],
   "source": [
    "\n",
    "lstm_v3_other_df_infos = {}\n",
    "\n",
    "for lstm_v3_procedure_path_infos_key in lstm_v3_procedure_path_infos.keys():\n",
    "  kfold_logs_path = f'{EXPR_PATH}/{lstm_v3_procedure_path_infos[lstm_v3_procedure_path_infos_key]}/'\n",
    "\n",
    "  sample_files = [sample_file.name for sample_file in sorted(Path(kfold_logs_path).iterdir(), key=os.path.getmtime) if sample_file.is_dir() and sample_file.name.startswith('run')]\n",
    "\n",
    "  kfold_logs_path = os.path.join(kfold_logs_path, sample_files[-1])\n",
    "  for __ in range(4):\n",
    "    kfold_logs_path = os.path.join(kfold_logs_path, os.listdir(kfold_logs_path)[0])\n",
    "\n",
    "  other_df = get_train_other_values_as_df_from_log_path(kfold_logs_path)\n",
    "  lstm_v3_other_df_infos[lstm_v3_procedure_path_infos_key] = other_df.copy()\n",
    "  print(lstm_v3_procedure_path_infos_key, other_df.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "lstm_v4_other_df_infos = {}\n",
    "\n",
    "for lstm_v4_procedure_path_infos_key in lstm_v4_procedure_path_infos.keys():\n",
    "  kfold_logs_path = f'{EXPR_PATH}/{lstm_v4_procedure_path_infos[lstm_v4_procedure_path_infos_key]}/'\n",
    "\n",
    "  sample_files = [sample_file.name for sample_file in sorted(Path(kfold_logs_path).iterdir(), key=os.path.getmtime) if sample_file.is_dir() and sample_file.name.startswith('run')]\n",
    "\n",
    "  kfold_logs_path = os.path.join(kfold_logs_path, sample_files[-1])\n",
    "  for __ in range(4):\n",
    "    kfold_logs_path = os.path.join(kfold_logs_path, os.listdir(kfold_logs_path)[0])\n",
    "\n",
    "  other_df = get_train_other_values_as_df_from_log_path(kfold_logs_path)\n",
    "  lstm_v4_other_df_infos[lstm_v4_procedure_path_infos_key] = other_df.copy()\n",
    "  print(lstm_v4_procedure_path_infos_key, other_df.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 12540,
     "status": "ok",
     "timestamp": 1738086423680,
     "user": {
      "displayName": "Furkan Ercelebi",
      "userId": "09395212391711469742"
     },
     "user_tz": -180
    },
    "id": "69ep2mYLA8-m",
    "outputId": "b45b18fb-3210-4f3f-ce14-42ad0e4ed34d"
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(6, 2, figsize=(30, 30))\n",
    "\n",
    "procedure_list = ['BLNC--ONL_ORG--ALL', \\\n",
    "                  'BLNC--ORG_AUG_SEP--ALL',\\\n",
    "                  'NON_BLNC--ORG_AUG_SEP--ALL',\\\n",
    "                  'BLNC--ORG_AUG_MIX--ALL', \\\n",
    "                  'NON_BLNC--ORG_AUG_MIX--ALL']\n",
    "\n",
    "for row_idx in range(6):\n",
    "\n",
    "  axes_idx = 0\n",
    "  if row_idx < 5:\n",
    "\n",
    "    main_log_df = lstm_v3_other_df_infos[f'{procedure_list[row_idx]}--NON_RAW'].copy()\n",
    "\n",
    "    sns.lineplot(data=main_log_df, x='Epoch', y='Ratio', hue=\"Phase\", ax=axes[row_idx][axes_idx])\n",
    "\n",
    "    procedure_components = procedure_list[row_idx].split('--')\n",
    "    axes[row_idx][axes_idx].set_title(f'LSTM V3 {procedure_components[0]}, {procedure_components[1]}, {procedure_components[2]}')\n",
    "    axes_idx += 1\n",
    "\n",
    "    main_log_df = lstm_v4_other_df_infos[procedure_list[row_idx]].copy()\n",
    "\n",
    "    sns.lineplot(data=main_log_df, x='Epoch', y='Ratio', hue=\"Phase\", ax=axes[row_idx][axes_idx])\n",
    "\n",
    "    procedure_components = procedure_list[row_idx].split('--')\n",
    "    axes[row_idx][axes_idx].set_title(f'LSTM V4 {procedure_components[0]}, {procedure_components[1]}, {procedure_components[2]}')\n",
    "    axes_idx += 1\n",
    "\n",
    "  else:\n",
    "\n",
    "    main_log_df = lstm_v3_other_df_infos[f'{procedure_list[3]}--RAW'].copy()\n",
    "\n",
    "    sns.lineplot(data=main_log_df, x='Epoch', y='Ratio', hue=\"Phase\", ax=axes[row_idx][axes_idx])\n",
    "\n",
    "    procedure_components = procedure_list[3].split('--')\n",
    "    axes[row_idx][axes_idx].set_title(f'LSTM V3 {procedure_components[0]}, {procedure_components[1]}, {procedure_components[2]}, RAW')\n",
    "    axes_idx += 1\n",
    "\n",
    "\n",
    "# Adjust the spacing between plots\n",
    "plt.tight_layout()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n",
    "\n",
    "# fig.savefig(f\"{model_name}_{experiment_procedure_name}_{(i + 1)}KFold.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1123,
     "status": "ok",
     "timestamp": 1737854191942,
     "user": {
      "displayName": "Furkan Ercelebi",
      "userId": "09395212391711469742"
     },
     "user_tz": -180
    },
    "id": "vun7mphFKR3z",
    "outputId": "9b75cc84-9cc6-451b-9f0a-4e01df796faa"
   },
   "outputs": [],
   "source": [
    "\n",
    "lstm_test_dataset_df_infos = {}\n",
    "print('LSTM Test Dataset Collectting')\n",
    "for lstm_procedure_path_infos_key in lstm_procedure_path_infos.keys():\n",
    "  kfold_logs_path = f'{EXPR_PATH}/{lstm_procedure_path_infos[lstm_procedure_path_infos_key]}/'\n",
    "\n",
    "  INPUT_DIR = os.path.join(kfold_logs_path, sorted([exp_fold for exp_fold in os.listdir(kfold_logs_path) if exp_fold.startswith('test_dataset')])[-1])\n",
    "\n",
    "  df = pd.read_csv(INPUT_DIR)\n",
    "  df = df.drop('Unnamed: 0', axis=1)\n",
    "  df['Diagnose'] = df['Diagnose'].apply(lambda x: 'No Stress' if x == 0 else 'Stress')\n",
    "  print(lstm_procedure_path_infos_key, df.columns)\n",
    "  lstm_test_dataset_df_infos[lstm_procedure_path_infos_key] = df.copy()\n",
    "\n",
    "\n",
    "\n",
    "lstm_v2_test_dataset_df_infos = {}\n",
    "print('LSTM Test Dataset Collectting')\n",
    "for lstm_v2_procedure_path_infos_key in lstm_v2_procedure_path_infos.keys():\n",
    "  kfold_logs_path = f'{EXPR_PATH}/{lstm_v2_procedure_path_infos[lstm_v2_procedure_path_infos_key]}/'\n",
    "\n",
    "  INPUT_DIR = os.path.join(kfold_logs_path, sorted([exp_fold for exp_fold in os.listdir(kfold_logs_path) if exp_fold.startswith('test_dataset')])[-1])\n",
    "\n",
    "  df = pd.read_csv(INPUT_DIR)\n",
    "  df = df.drop('Unnamed: 0', axis=1)\n",
    "  df['Diagnose'] = df['Diagnose'].apply(lambda x: 'No Stress' if x == 0 else 'Stress')\n",
    "  print(lstm_v2_procedure_path_infos_key, df.columns)\n",
    "  lstm_v2_test_dataset_df_infos[lstm_v2_procedure_path_infos_key] = df.copy()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "alexnet_test_dataset_df_infos = {}\n",
    "print('AlexNet Test Dataset Collectting')\n",
    "for alexnet_procedure_path_infos_key in alexnet_procedure_path_infos.keys():\n",
    "  kfold_logs_path = f'{EXPR_PATH}/{alexnet_procedure_path_infos[alexnet_procedure_path_infos_key]}/'\n",
    "\n",
    "  INPUT_DIR = os.path.join(kfold_logs_path, sorted([exp_fold for exp_fold in os.listdir(kfold_logs_path) if exp_fold.startswith('test_dataset')])[-1])\n",
    "\n",
    "  df = pd.read_csv(INPUT_DIR)\n",
    "  df = df.drop('Unnamed: 0', axis=1)\n",
    "  df['Diagnose'] = df['Diagnose'].apply(lambda x: 'No Stress' if x == 0 else 'Stress')\n",
    "  print(alexnet_procedure_path_infos_key, df.columns)\n",
    "  alexnet_test_dataset_df_infos[alexnet_procedure_path_infos_key] = df.copy()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 6384,
     "status": "error",
     "timestamp": 1738144170660,
     "user": {
      "displayName": "İbrahim Furkan",
      "userId": "03214658540359897285"
     },
     "user_tz": -180
    },
    "id": "4YWDMi3LBS-w",
    "outputId": "dfefe359-41b1-45dd-cb63-596bd6142746"
   },
   "outputs": [],
   "source": [
    "\n",
    "lstm_v3_test_dataset_df_infos = {}\n",
    "print('LSTM V3 Test Dataset Collectting')\n",
    "for lstm_v3_procedure_path_infos_key in lstm_v3_procedure_path_infos.keys():\n",
    "  kfold_logs_path = f'{EXPR_PATH}/{lstm_v3_procedure_path_infos[lstm_v3_procedure_path_infos_key]}/'\n",
    "\n",
    "  INPUT_DIR = os.path.join(kfold_logs_path, sorted([exp_fold for exp_fold in os.listdir(kfold_logs_path) if exp_fold.startswith('test_dataset')])[-1])\n",
    "\n",
    "  df = pd.read_csv(INPUT_DIR)\n",
    "  df = df.drop('Unnamed: 0', axis=1)\n",
    "  df['Diagnose'] = df['Diagnose'].apply(lambda x: 'No Stress' if x == 0 else 'Stress')\n",
    "  print(lstm_v3_procedure_path_infos_key, df.columns)\n",
    "  lstm_v3_test_dataset_df_infos[lstm_v3_procedure_path_infos_key] = df.copy()\n",
    "\n",
    "lstm_v4_test_dataset_df_infos = {}\n",
    "print('LSTM V4 Test Dataset Collectting')\n",
    "for lstm_v4_procedure_path_infos_key in lstm_v4_procedure_path_infos.keys():\n",
    "  kfold_logs_path = f'{EXPR_PATH}/{lstm_v4_procedure_path_infos[lstm_v4_procedure_path_infos_key]}/'\n",
    "\n",
    "  INPUT_DIR = os.path.join(kfold_logs_path, sorted([exp_fold for exp_fold in os.listdir(kfold_logs_path) if exp_fold.startswith('test_dataset')])[-1])\n",
    "\n",
    "  df = pd.read_csv(INPUT_DIR)\n",
    "  df = df.drop('Unnamed: 0', axis=1)\n",
    "  df['Diagnose'] = df['Diagnose'].apply(lambda x: 'No Stress' if x == 0 else 'Stress')\n",
    "  print(lstm_v4_procedure_path_infos_key, df.columns)\n",
    "  lstm_v4_test_dataset_df_infos[lstm_v4_procedure_path_infos_key] = df.copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 513,
     "status": "ok",
     "timestamp": 1738144177558,
     "user": {
      "displayName": "İbrahim Furkan",
      "userId": "03214658540359897285"
     },
     "user_tz": -180
    },
    "id": "THDsOGG7MpHI"
   },
   "outputs": [],
   "source": [
    "# from this site https://christianbernecker.medium.com/how-to-create-a-confusion-matrix-in-pytorch-38d06a7f04b7\n",
    "def test_model_without_save_as_image(model , model_name,device, test_loader, result_classes):\n",
    "\n",
    "        y_pred = []\n",
    "        y_true = []\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for data in test_loader:\n",
    "\n",
    "                images, labels = data[0].to(device), data[1].to(device)\n",
    "                outputs = model(images)\n",
    "\n",
    "                # _, predicted = torch.max(outputs.data, 1)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                output = (predicted).data.cpu().numpy()\n",
    "                y_pred.extend(output) # Save Prediction\n",
    "\n",
    "                # Convert labels to class indices before comparison:\n",
    "                labels_indices = torch.argmax(labels, dim=1)  # Get indices from one-hot labels\n",
    "                labels_np = labels_indices.data.cpu().numpy()  # Convert to NumPy for y_true\n",
    "                y_true.extend(labels_np) # Save Truth\n",
    "\n",
    "                total += labels_np.shape[0] # Get the number of labels using .shape[0] for NumPy array\n",
    "                # total += labels.size(0)\n",
    "                # Compare predicted indices with true indices\n",
    "                correct += (predicted == labels_indices).sum().item()\n",
    "\n",
    "        ty_pred = torch.tensor(y_pred)\n",
    "        ty_true = torch.tensor(y_true)\n",
    "\n",
    "        # Build confusion matrix\n",
    "        cf_matrix = confusion_matrix(y_true, y_pred)\n",
    "        df_cm = pd.DataFrame(cf_matrix, index = [i for i in result_classes],\n",
    "                            columns = [i for i in result_classes])\n",
    "\n",
    "        return (df_cm, correct, total, binary_accuracy(ty_pred, ty_true), binary_recall(ty_pred, ty_true), binary_precision(ty_pred, ty_true), binary_f1_score(ty_pred, ty_true))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9506,
     "status": "ok",
     "timestamp": 1737858485105,
     "user": {
      "displayName": "Furkan Ercelebi",
      "userId": "09395212391711469742"
     },
     "user_tz": -180
    },
    "id": "lDt5b1LxP-q2",
    "outputId": "fe027905-def5-4ee7-c136-aa88a260d64a"
   },
   "outputs": [],
   "source": [
    "\n",
    "lstm_best_model_infos = {}\n",
    "print('LSTM Test Dataset Collectting')\n",
    "for lstm_procedure_path_infos_key in lstm_procedure_path_infos.keys():\n",
    "\n",
    "  model_expr_path = os.path.join(EXPR_PATH, lstm_procedure_path_infos[lstm_procedure_path_infos_key])\n",
    "  latest_exp_folder = os.path.join(model_expr_path, sorted([exp_fold for exp_fold in os.listdir(model_expr_path) if exp_fold.startswith('modelPerformance')])[-1])\n",
    "\n",
    "  for __ in range(2):\n",
    "    latest_exp_folder = os.path.join(latest_exp_folder, os.listdir(latest_exp_folder)[0])\n",
    "\n",
    "  best_model=torch.load(os.path.join(latest_exp_folder, (sorted(os.listdir(latest_exp_folder))[-1])))\n",
    "  lstm_best_model_infos[lstm_procedure_path_infos_key] = copy.deepcopy(best_model)\n",
    "\n",
    "\n",
    "\n",
    "lstm_v2_best_model_infos = {}\n",
    "print('LSTM V2 Test Dataset Collectting')\n",
    "for lstm_v2_procedure_path_infos_key in lstm_v2_procedure_path_infos.keys():\n",
    "\n",
    "  model_expr_path = os.path.join(EXPR_PATH, lstm_v2_procedure_path_infos[lstm_v2_procedure_path_infos_key])\n",
    "  latest_exp_folder = os.path.join(model_expr_path, sorted([exp_fold for exp_fold in os.listdir(model_expr_path) if exp_fold.startswith('modelPerformance')])[-1])\n",
    "\n",
    "  for __ in range(2):\n",
    "    latest_exp_folder = os.path.join(latest_exp_folder, os.listdir(latest_exp_folder)[0])\n",
    "\n",
    "  best_model=torch.load(os.path.join(latest_exp_folder, (sorted(os.listdir(latest_exp_folder))[-1])))\n",
    "  lstm_v2_best_model_infos[lstm_v2_procedure_path_infos_key] = copy.deepcopy(best_model)\n",
    "\n",
    "\n",
    "alexnet_best_model_infos = {}\n",
    "print('AlexNet Test Dataset Collectting')\n",
    "for alexnet_test_dataset_df_infos_keys in alexnet_test_dataset_df_infos.keys():\n",
    "  # df = alexnet_test_dataset_df_infos[alexnet_test_dataset_df_infos_keys].copy()\n",
    "  # df_without_diagnose = df.drop('Diagnose', axis=1)\n",
    "  # dataset_test = get_samples_as_dataloader(df_without_diagnose.values, df['Diagnose'].values, True)\n",
    "\n",
    "  model_expr_path = os.path.join(EXPR_PATH, alexnet_procedure_path_infos[alexnet_test_dataset_df_infos_keys])\n",
    "  latest_exp_folder = os.path.join(model_expr_path, sorted([exp_fold for exp_fold in os.listdir(model_expr_path) if exp_fold.startswith('modelPerformance')])[-1])\n",
    "\n",
    "  for __ in range(2):\n",
    "    latest_exp_folder = os.path.join(latest_exp_folder, os.listdir(latest_exp_folder)[0])\n",
    "\n",
    "  best_model=torch.load(os.path.join(latest_exp_folder, (sorted(os.listdir(latest_exp_folder))[-1])))\n",
    "  alexnet_best_model_infos[alexnet_test_dataset_df_infos_keys] = copy.deepcopy(best_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13743,
     "status": "ok",
     "timestamp": 1738144198343,
     "user": {
      "displayName": "İbrahim Furkan",
      "userId": "03214658540359897285"
     },
     "user_tz": -180
    },
    "id": "-Krayr3eB6xV",
    "outputId": "c673838c-89da-407c-94b7-ae7e6771567b"
   },
   "outputs": [],
   "source": [
    "\n",
    "lstm_v3_best_model_infos = {}\n",
    "print('LSTM V3 Model Collectting')\n",
    "for lstm_v3_procedure_path_infos_key in lstm_v3_procedure_path_infos.keys():\n",
    "\n",
    "  model_expr_path = os.path.join(EXPR_PATH, lstm_v3_procedure_path_infos[lstm_v3_procedure_path_infos_key])\n",
    "  latest_exp_folder = os.path.join(model_expr_path, sorted([exp_fold for exp_fold in os.listdir(model_expr_path) if exp_fold.startswith('modelPerformance')])[-1])\n",
    "\n",
    "  for __ in range(2):\n",
    "    latest_exp_folder = os.path.join(latest_exp_folder, os.listdir(latest_exp_folder)[0])\n",
    "\n",
    "  best_model=torch.load(os.path.join(latest_exp_folder, (sorted(os.listdir(latest_exp_folder))[-1])))\n",
    "  lstm_v3_best_model_infos[lstm_v3_procedure_path_infos_key] = copy.deepcopy(best_model)\n",
    "\n",
    "\n",
    "lstm_v4_best_model_infos = {}\n",
    "print('LSTM V4 Model Collectting')\n",
    "for lstm_v4_procedure_path_infos_key in lstm_v4_procedure_path_infos.keys():\n",
    "\n",
    "  model_expr_path = os.path.join(EXPR_PATH, lstm_v4_procedure_path_infos[lstm_v4_procedure_path_infos_key])\n",
    "  latest_exp_folder = os.path.join(model_expr_path, sorted([exp_fold for exp_fold in os.listdir(model_expr_path) if exp_fold.startswith('modelPerformance')])[-1])\n",
    "\n",
    "  for __ in range(2):\n",
    "    latest_exp_folder = os.path.join(latest_exp_folder, os.listdir(latest_exp_folder)[0])\n",
    "\n",
    "  best_model=torch.load(os.path.join(latest_exp_folder, (sorted(os.listdir(latest_exp_folder))[-1])))\n",
    "  lstm_v4_best_model_infos[lstm_v4_procedure_path_infos_key] = copy.deepcopy(best_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3059,
     "status": "ok",
     "timestamp": 1737858492410,
     "user": {
      "displayName": "Furkan Ercelebi",
      "userId": "09395212391711469742"
     },
     "user_tz": -180
    },
    "id": "e6QeeWHETEes",
    "outputId": "28e26d4c-a29e-41e5-b238-235ce1dda0d8"
   },
   "outputs": [],
   "source": [
    "\n",
    "lstm_test_results_infos = {}\n",
    "print('LSTM Test Dataset Collectting')\n",
    "for lstm_procedure_path_infos_key in lstm_procedure_path_infos.keys():\n",
    "\n",
    "  df = lstm_test_dataset_df_infos[lstm_procedure_path_infos_key].copy()\n",
    "  df_without_diagnose = df.drop('Diagnose', axis=1)\n",
    "  y_test = df['Diagnose'].values\n",
    "  dataset_test = get_samples_as_dataloader(df_without_diagnose.values, y_test, True)\n",
    "\n",
    "  classes = np.unique(y_test)\n",
    "  le = OneHotEncoder()\n",
    "  classes_idx = le.fit_transform(classes.reshape(-1, 1)).toarray()\n",
    "\n",
    "  class_dict = { cls : cls_idx for cls, cls_idx in zip(classes, classes_idx)}\n",
    "  # sorted_class_list = sorted(class_dict.items(), key=lambda kv: (kv[1], kv[0]))\n",
    "  # sorted_class_labels = [d_key for d_key in dict(sorted_class_list).keys()]\n",
    "  sorted_class_labels = class_dict\n",
    "\n",
    "  dataset_test_loader = DataLoader(dataset_test, shuffle=True, batch_size=10 if 'MIX' in lstm_procedure_path_infos_key else 5)\n",
    "  lstm_test_results_infos[lstm_procedure_path_infos_key] = test_model_without_save_as_image(lstm_best_model_infos[lstm_procedure_path_infos_key], f'LSTM_{lstm_procedure_path_infos_key}','cpu', dataset_test_loader, sorted_class_labels)\n",
    "\n",
    "\n",
    "\n",
    "lstm_v2_test_results_infos = {}\n",
    "print('LSTM V2 Test Dataset Collectting')\n",
    "for lstm_v2_procedure_path_infos_key in lstm_v2_procedure_path_infos.keys():\n",
    "\n",
    "  df = lstm_v2_test_dataset_df_infos[lstm_v2_procedure_path_infos_key].copy()\n",
    "  df_without_diagnose = df.drop('Diagnose', axis=1)\n",
    "  y_test = df['Diagnose'].values\n",
    "  dataset_test = get_samples_as_dataloader(df_without_diagnose.values, y_test, True)\n",
    "\n",
    "  classes = np.unique(y_test)\n",
    "  le = OneHotEncoder()\n",
    "  classes_idx = le.fit_transform(classes.reshape(-1, 1)).toarray()\n",
    "\n",
    "  class_dict = { cls : cls_idx for cls, cls_idx in zip(classes, classes_idx)}\n",
    "  # sorted_class_list = sorted(class_dict.items(), key=lambda kv: (kv[1], kv[0]))\n",
    "  # sorted_class_labels = [d_key for d_key in dict(sorted_class_list).keys()]\n",
    "  sorted_class_labels = class_dict\n",
    "\n",
    "  dataset_test_loader = DataLoader(dataset_test, shuffle=True, batch_size=10 if 'MIX' in lstm_v2_procedure_path_infos_key else 5)\n",
    "  lstm_v2_test_results_infos[lstm_v2_procedure_path_infos_key] = test_model_without_save_as_image(lstm_v2_best_model_infos[lstm_v2_procedure_path_infos_key], f'LSTM_V2_{lstm_v2_procedure_path_infos_key}','cpu', dataset_test_loader, sorted_class_labels)\n",
    "\n",
    "\n",
    "alexnet_test_results_infos = {}\n",
    "for alexnet_test_dataset_df_infos_keys in alexnet_test_dataset_df_infos.keys():\n",
    "  df = alexnet_test_dataset_df_infos[alexnet_test_dataset_df_infos_keys].copy()\n",
    "  df_without_diagnose = df.drop('Diagnose', axis=1)\n",
    "  y_test = df['Diagnose'].values\n",
    "  dataset_test = get_samples_as_dataloader(df_without_diagnose.values, y_test)\n",
    "\n",
    "  classes = np.unique(y_test)\n",
    "  le = OneHotEncoder()\n",
    "  classes_idx = le.fit_transform(classes.reshape(-1, 1)).toarray()\n",
    "\n",
    "  class_dict = { cls : cls_idx for cls, cls_idx in zip(classes, classes_idx)}\n",
    "  # sorted_class_list = sorted(class_dict.items(), key=lambda kv: (kv[1], kv[0]))\n",
    "  # sorted_class_labels = [d_key for d_key in dict(sorted_class_list).keys()]\n",
    "  sorted_class_labels = class_dict\n",
    "\n",
    "  dataset_test_loader = DataLoader(dataset_test, shuffle=True, batch_size=10 if 'MIX' in alexnet_test_dataset_df_infos_keys else 5)\n",
    "  alexnet_test_results_infos[alexnet_test_dataset_df_infos_keys] = test_model_without_save_as_image(alexnet_best_model_infos[alexnet_test_dataset_df_infos_keys], f'AlexNet_{alexnet_test_dataset_df_infos_keys}','cpu', dataset_test_loader, sorted_class_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1424,
     "status": "ok",
     "timestamp": 1738144214689,
     "user": {
      "displayName": "İbrahim Furkan",
      "userId": "03214658540359897285"
     },
     "user_tz": -180
    },
    "id": "RTVTkC0kCXOb",
    "outputId": "5f775938-32e1-430c-8947-83dbe74cd35b"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "lstm_v3_test_results_infos = {}\n",
    "print('LSTM V3 Test Result Collectting')\n",
    "for lstm_v3_procedure_path_infos_key in lstm_v3_procedure_path_infos.keys():\n",
    "\n",
    "  df = lstm_v3_test_dataset_df_infos[lstm_v3_procedure_path_infos_key].copy()\n",
    "  df_without_diagnose = df.drop('Diagnose', axis=1)\n",
    "  y_test = df['Diagnose'].values\n",
    "  dataset_test = get_samples_as_dataloader(df_without_diagnose.values, y_test, True)\n",
    "\n",
    "  classes = np.unique(y_test)\n",
    "  le = OneHotEncoder()\n",
    "  classes_idx = le.fit_transform(classes.reshape(-1, 1)).toarray()\n",
    "\n",
    "  class_dict = { cls : cls_idx for cls, cls_idx in zip(classes, classes_idx)}\n",
    "  # sorted_class_list = sorted(class_dict.items(), key=lambda kv: (kv[1], kv[0]))\n",
    "  # sorted_class_labels = [d_key for d_key in dict(sorted_class_list).keys()]\n",
    "  sorted_class_labels = class_dict\n",
    "\n",
    "  dataset_test_loader = DataLoader(dataset_test, shuffle=True, batch_size=10 if 'MIX' in lstm_v3_procedure_path_infos_key else 5)\n",
    "  lstm_v3_test_results_infos[lstm_v3_procedure_path_infos_key] = test_model_without_save_as_image(lstm_v3_best_model_infos[lstm_v3_procedure_path_infos_key], f'LSTM_V3_{lstm_v3_procedure_path_infos_key}','cpu', dataset_test_loader, sorted_class_labels)\n",
    "\n",
    "\n",
    "lstm_v4_test_results_infos = {}\n",
    "print('LSTM V4 Test Result Collectting')\n",
    "for lstm_v4_procedure_path_infos_key in lstm_v4_procedure_path_infos.keys():\n",
    "\n",
    "   df = lstm_v4_test_dataset_df_infos[lstm_v4_procedure_path_infos_key].copy()\n",
    "   df_without_diagnose = df.drop('Diagnose', axis=1)\n",
    "   y_test = df['Diagnose'].values\n",
    "   dataset_test = get_samples_as_dataloader(df_without_diagnose.values, y_test, True)\n",
    "\n",
    "   classes = np.unique(y_test)\n",
    "   le = OneHotEncoder()\n",
    "   classes_idx = le.fit_transform(classes.reshape(-1, 1)).toarray()\n",
    "   class_dict = { cls : cls_idx for cls, cls_idx in zip(classes, classes_idx)}\n",
    "   # sorted_class_list = sorted(class_dict.items(), key=lambda kv: (kv[1], kv[0]))\n",
    "   # sorted_class_labels = [d_key for d_key in dict(sorted_class_list).keys()]\n",
    "   sorted_class_labels = class_dict\n",
    "\n",
    "   dataset_test_loader = DataLoader(dataset_test, shuffle=True, batch_size=10 if 'MIX' in lstm_v4_procedure_path_infos_key else 5)\n",
    "   lstm_v4_test_results_infos[lstm_v4_procedure_path_infos_key] = test_model_without_save_as_image(lstm_v4_best_model_infos[lstm_v4_procedure_path_infos_key], f'LSTM_V4_{lstm_v4_procedure_path_infos_key}','cpu', dataset_test_loader, sorted_class_labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 46390,
     "status": "ok",
     "timestamp": 1737858825459,
     "user": {
      "displayName": "Furkan Ercelebi",
      "userId": "09395212391711469742"
     },
     "user_tz": -180
    },
    "id": "v5aTalv9VhVC",
    "outputId": "a40faa66-af30-48f7-a28a-93c0678d330d"
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(6, 6, figsize=(30, 30))\n",
    "\n",
    "procedure_list = ['BLNC--ONL_ORG', \\\n",
    "                  'NON_BLNC--ONL_ORG', \\\n",
    "                  'BLNC--ORG_AUG_SEP',\\\n",
    "                  'NON_BLNC--ORG_AUG_SEP',\\\n",
    "                  'BLNC--ORG_AUG_MIX', \\\n",
    "                  'NON_BLNC--ORG_AUG_MIX']\n",
    "\n",
    "axes_idx = 0\n",
    "\n",
    "for row_idx in range(6):\n",
    "\n",
    "  result_components = alexnet_test_results_infos[f'{procedure_list[row_idx]}--ALL']\n",
    "  df_cm = alexnet_test_results_infos[f'{procedure_list[row_idx]}--ALL'][0].copy()\n",
    "  sns.heatmap(df_cm, annot=True, fmt='g', ax=axes[row_idx][0])\n",
    "  procedure_components = procedure_list[row_idx].split('--')\n",
    "  axes_title = f'AlexNet {procedure_components[0]}, {procedure_components[1]}, ALL'\n",
    "  axes[row_idx][0].set_title(axes_title)\n",
    "  print(axes_title)\n",
    "  print('Correct Prediction: {:d}  Total Samples: {:d}'.format(result_components[1], result_components[2]))\n",
    "  print('Test Accuracy = {:f}'.format(result_components[3]))\n",
    "  print('Test F1 Score = {:f}'.format(result_components[4]))\n",
    "  print('Test Precision = {:f}'.format(result_components[5]))\n",
    "  print('Test Recal = {:f}'.format(result_components[6]))\n",
    "\n",
    "  result_components = alexnet_test_results_infos[f'{procedure_list[row_idx]}--TD']\n",
    "  df_cm = alexnet_test_results_infos[f'{procedure_list[row_idx]}--TD'][0].copy()\n",
    "  sns.heatmap(df_cm, annot=True, fmt='g', ax=axes[row_idx][1])\n",
    "  procedure_components = procedure_list[row_idx].split('--')\n",
    "  axes_title = f'AlexNet {procedure_components[0]}, {procedure_components[1]}, TD'\n",
    "  axes[row_idx][1].set_title(axes_title)\n",
    "  print(axes_title)\n",
    "  print('Correct Prediction: {:d}  Total Samples: {:d}'.format(result_components[1], result_components[2]))\n",
    "  print('Test Accuracy = {:f}'.format(result_components[3]))\n",
    "  print('Test F1 Score = {:f}'.format(result_components[4]))\n",
    "  print('Test Precision = {:f}'.format(result_components[5]))\n",
    "  print('Test Recal = {:f}'.format(result_components[6]))\n",
    "\n",
    "  result_components = lstm_test_results_infos[f'{procedure_list[row_idx]}--ALL']\n",
    "  df_cm = lstm_test_results_infos[f'{procedure_list[row_idx]}--ALL'][0].copy()\n",
    "  sns.heatmap(df_cm, annot=True, fmt='g', ax=axes[row_idx][2])\n",
    "  procedure_components = procedure_list[row_idx].split('--')\n",
    "  axes_title = f'LSTM {procedure_components[0]}, {procedure_components[1]}, ALL'\n",
    "  axes[row_idx][2].set_title(axes_title)\n",
    "  print(axes_title)\n",
    "  print('Correct Prediction: {:d}  Total Samples: {:d}'.format(result_components[1], result_components[2]))\n",
    "  print('Test Accuracy = {:f}'.format(result_components[3]))\n",
    "  print('Test F1 Score = {:f}'.format(result_components[4]))\n",
    "  print('Test Precision = {:f}'.format(result_components[5]))\n",
    "  print('Test Recal = {:f}'.format(result_components[6]))\n",
    "\n",
    "\n",
    "  result_components = lstm_test_results_infos[f'{procedure_list[row_idx]}--TD']\n",
    "  df_cm = lstm_test_results_infos[f'{procedure_list[row_idx]}--TD'][0].copy()\n",
    "  sns.heatmap(df_cm, annot=True, fmt='g', ax=axes[row_idx][3])\n",
    "  procedure_components = procedure_list[row_idx].split('--')\n",
    "  axes_title = f'LSTM {procedure_components[0]}, {procedure_components[1]}, TD'\n",
    "  axes[row_idx][3].set_title(axes_title)\n",
    "  print(axes_title)\n",
    "  print('Correct Prediction: {:d}  Total Samples: {:d}'.format(result_components[1], result_components[2]))\n",
    "  print('Test Accuracy = {:f}'.format(result_components[3]))\n",
    "  print('Test F1 Score = {:f}'.format(result_components[4]))\n",
    "  print('Test Precision = {:f}'.format(result_components[5]))\n",
    "  print('Test Recal = {:f}'.format(result_components[6]))\n",
    "\n",
    "\n",
    "  result_components = lstm_v2_test_results_infos[f'{procedure_list[row_idx]}--ALL']\n",
    "  df_cm = lstm_v2_test_results_infos[f'{procedure_list[row_idx]}--ALL'][0].copy()\n",
    "  sns.heatmap(df_cm, annot=True, fmt='g', ax=axes[row_idx][4])\n",
    "  procedure_components = procedure_list[row_idx].split('--')\n",
    "  axes_title = f'LSTM V2 {procedure_components[0]}, {procedure_components[1]}, ALL'\n",
    "  axes[row_idx][4].set_title(axes_title)\n",
    "  print(axes_title)\n",
    "  print('Correct Prediction: {:d}  Total Samples: {:d}'.format(result_components[1], result_components[2]))\n",
    "  print('Test Accuracy = {:f}'.format(result_components[3]))\n",
    "  print('Test F1 Score = {:f}'.format(result_components[4]))\n",
    "  print('Test Precision = {:f}'.format(result_components[5]))\n",
    "  print('Test Recal = {:f}'.format(result_components[6]))\n",
    "\n",
    "\n",
    "  result_components = lstm_v2_test_results_infos[f'{procedure_list[row_idx]}--TD']\n",
    "  df_cm = lstm_v2_test_results_infos[f'{procedure_list[row_idx]}--TD'][0].copy()\n",
    "  sns.heatmap(df_cm, annot=True, fmt='g', ax=axes[row_idx][5])\n",
    "  procedure_components = procedure_list[row_idx].split('--')\n",
    "  axes_title = f'LSTM V2  {procedure_components[0]}, {procedure_components[1]}, TD'\n",
    "  axes[row_idx][5].set_title(axes_title)\n",
    "  print(axes_title)\n",
    "  print('Correct Prediction: {:d}  Total Samples: {:d}'.format(result_components[1], result_components[2]))\n",
    "  print('Test Accuracy = {:f}'.format(result_components[3]))\n",
    "  print('Test F1 Score = {:f}'.format(result_components[4]))\n",
    "  print('Test Precision = {:f}'.format(result_components[5]))\n",
    "  print('Test Recal = {:f}'.format(result_components[6]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 10939,
     "status": "ok",
     "timestamp": 1738144270619,
     "user": {
      "displayName": "İbrahim Furkan",
      "userId": "03214658540359897285"
     },
     "user_tz": -180
    },
    "id": "5AzenRUTCr7Q",
    "outputId": "dd88e398-9f27-41e3-b440-fb3cf384c17f"
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(6, 2, figsize=(30, 30))\n",
    "\n",
    "procedure_list = ['BLNC--ONL_ORG--ALL', \\\n",
    "                  'BLNC--ORG_AUG_SEP--ALL',\\\n",
    "                  'NON_BLNC--ORG_AUG_SEP--ALL',\\\n",
    "                  'BLNC--ORG_AUG_MIX--ALL', \\\n",
    "                  'NON_BLNC--ORG_AUG_MIX--ALL']\n",
    "\n",
    "axes_idx = 0\n",
    "\n",
    "for row_idx in range(6):\n",
    "\n",
    "  if row_idx < 5:\n",
    "    result_components = lstm_v3_test_results_infos[f'{procedure_list[row_idx]}--NON_RAW']\n",
    "    df_cm = lstm_v3_test_results_infos[f'{procedure_list[row_idx]}--NON_RAW'][0].copy()\n",
    "    sns.heatmap(df_cm, annot=True, fmt='g', ax=axes[row_idx][0])\n",
    "    procedure_components = procedure_list[row_idx].split('--')\n",
    "    axes_title = f'LSTM V3 {procedure_components[0]}, {procedure_components[1]}, {procedure_components[2]}, NON RAW'\n",
    "    axes[row_idx][0].set_title(axes_title)\n",
    "    print(axes_title)\n",
    "    print('Correct Prediction: {:d}  Total Samples: {:d}'.format(result_components[1], result_components[2]))\n",
    "    print('Test Accuracy = {:f}'.format(result_components[3]))\n",
    "    print('Test F1 Score = {:f}'.format(result_components[4]))\n",
    "    print('Test Precision = {:f}'.format(result_components[5]))\n",
    "    print('Test Recal = {:f}'.format(result_components[6]))\n",
    "\n",
    "\n",
    "    result_components = lstm_v4_test_results_infos[procedure_list[row_idx]]\n",
    "    df_cm = lstm_v4_test_results_infos[procedure_list[row_idx]][0].copy()\n",
    "    sns.heatmap(df_cm, annot=True, fmt='g', ax=axes[row_idx][1])\n",
    "    procedure_components = procedure_list[row_idx].split('--')\n",
    "    axes_title = f'LSTM V4 {procedure_components[0]}, {procedure_components[1]}, {procedure_components[2]}, TD'\n",
    "    axes[row_idx][1].set_title(axes_title)\n",
    "    print(axes_title)\n",
    "    print('Correct Prediction: {:d}  Total Samples: {:d}'.format(result_components[1], result_components[2]))\n",
    "    print('Test Accuracy = {:f}'.format(result_components[3]))\n",
    "    print('Test F1 Score = {:f}'.format(result_components[4]))\n",
    "    print('Test Precision = {:f}'.format(result_components[5]))\n",
    "    print('Test Recal = {:f}'.format(result_components[6]))\n",
    "\n",
    "  else:\n",
    "\n",
    "    result_components = lstm_v3_test_results_infos[f'{procedure_list[3]}--RAW']\n",
    "    df_cm = lstm_v3_test_results_infos[f'{procedure_list[3]}--RAW'][0].copy()\n",
    "    sns.heatmap(df_cm, annot=True, fmt='g', ax=axes[row_idx][0])\n",
    "    procedure_components = procedure_list[3].split('--')\n",
    "    axes_title = f'LSTM V3 {procedure_components[0]}, {procedure_components[1]}, {procedure_components[2]}, RAW'\n",
    "    axes[row_idx][0].set_title(axes_title)\n",
    "    print(axes_title)\n",
    "    print('Correct Prediction: {:d}  Total Samples: {:d}'.format(result_components[1], result_components[2]))\n",
    "    print('Test Accuracy = {:f}'.format(result_components[3]))\n",
    "    print('Test F1 Score = {:f}'.format(result_components[4]))\n",
    "    print('Test Precision = {:f}'.format(result_components[5]))\n",
    "    print('Test Recal = {:f}'.format(result_components[6]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xccw9LYUlVHN"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "fYWcwUKQkp4_",
    "A4SrFuxnlVHM"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
